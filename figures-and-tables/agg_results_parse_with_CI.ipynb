{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mean_acc</th>\n",
       "      <th>mean_acc_ci</th>\n",
       "      <th>mean_Macro_F1</th>\n",
       "      <th>mean_Macro_F1_ci</th>\n",
       "      <th>mean_MCC</th>\n",
       "      <th>mean_MCC_ci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>google/gemma-2-27b-it</td>\n",
       "      <td>0.6053</td>\n",
       "      <td>0.0231</td>\n",
       "      <td>0.5056</td>\n",
       "      <td>0.0154</td>\n",
       "      <td>0.5427</td>\n",
       "      <td>0.0213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>google/gemma-2-2b-it</td>\n",
       "      <td>0.4353</td>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.3262</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.3325</td>\n",
       "      <td>0.0187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>google/gemma-2-9b-it</td>\n",
       "      <td>0.6210</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.5350</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.5513</td>\n",
       "      <td>0.0191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>meta-llama/Llama-2-13b-chat-hf</td>\n",
       "      <td>0.0893</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0612</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>-0.0069</td>\n",
       "      <td>0.0136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>meta-llama/Llama-2-7b-chat-hf</td>\n",
       "      <td>0.0640</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.0269</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>meta-llama/Meta-Llama-3-8B-Instruct</td>\n",
       "      <td>0.3303</td>\n",
       "      <td>0.0134</td>\n",
       "      <td>0.2644</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.2538</td>\n",
       "      <td>0.0167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>meta-llama/Meta-Llama-3.1-8B-Instruct</td>\n",
       "      <td>0.2487</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.2180</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.1638</td>\n",
       "      <td>0.0193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.1</td>\n",
       "      <td>0.2360</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.1733</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.0886</td>\n",
       "      <td>0.0233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RuterNorway/Llama-2-13b-chat-norwegian</td>\n",
       "      <td>0.2327</td>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.1979</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.1459</td>\n",
       "      <td>0.0205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RuterNorway/Llama-2-7b-chat-norwegian</td>\n",
       "      <td>0.1080</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0280</td>\n",
       "      <td>0.0151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bineric/NorskGPT-Llama3-8b</td>\n",
       "      <td>0.1687</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>0.1514</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0614</td>\n",
       "      <td>0.0190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bineric/NorskGPT-Mistral-7b</td>\n",
       "      <td>0.3050</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.2689</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.2254</td>\n",
       "      <td>0.0147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>google/gemma-2-27b</td>\n",
       "      <td>0.1507</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.1397</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>google/gemma-2-2b</td>\n",
       "      <td>0.1643</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.1308</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.0498</td>\n",
       "      <td>0.0134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>google/gemma-2-9b</td>\n",
       "      <td>0.2080</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.1702</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0751</td>\n",
       "      <td>0.0141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>meta-llama/Meta-Llama-3-8B</td>\n",
       "      <td>0.1623</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.1416</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0338</td>\n",
       "      <td>0.0157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>meta-llama/Meta-Llama-3.1-8B</td>\n",
       "      <td>0.1707</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.1448</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0436</td>\n",
       "      <td>0.0170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mistralai/Mistral-7B-v0.1</td>\n",
       "      <td>0.1287</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.1031</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>-0.0020</td>\n",
       "      <td>0.0062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>norallm/normistral-7b-scratch</td>\n",
       "      <td>0.1647</td>\n",
       "      <td>0.0109</td>\n",
       "      <td>0.1389</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.0151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>norallm/normistral-7b-warm</td>\n",
       "      <td>0.1783</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.1376</td>\n",
       "      <td>0.0127</td>\n",
       "      <td>0.0231</td>\n",
       "      <td>0.0154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NorwAI/NorwAI-Mistral-7B</td>\n",
       "      <td>0.1683</td>\n",
       "      <td>0.0119</td>\n",
       "      <td>0.1255</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.0146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>norallm/normistral-7b-warm-instruct</td>\n",
       "      <td>0.1830</td>\n",
       "      <td>0.0134</td>\n",
       "      <td>0.0972</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NorwAI/NorwAI-Mistral-7B-instruct</td>\n",
       "      <td>0.1717</td>\n",
       "      <td>0.0169</td>\n",
       "      <td>0.1355</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>0.0167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     model  mean_acc  mean_acc_ci  \\\n",
       "14                   google/gemma-2-27b-it    0.6053       0.0231   \n",
       "12                    google/gemma-2-2b-it    0.4353       0.0215   \n",
       "13                    google/gemma-2-9b-it    0.6210       0.0180   \n",
       "22          meta-llama/Llama-2-13b-chat-hf    0.0893       0.0077   \n",
       "21           meta-llama/Llama-2-7b-chat-hf    0.0640       0.0071   \n",
       "19     meta-llama/Meta-Llama-3-8B-Instruct    0.3303       0.0134   \n",
       "11   meta-llama/Meta-Llama-3.1-8B-Instruct    0.2487       0.0113   \n",
       "20      mistralai/Mistral-7B-Instruct-v0.1    0.2360       0.0174   \n",
       "1   RuterNorway/Llama-2-13b-chat-norwegian    0.2327       0.0198   \n",
       "0    RuterNorway/Llama-2-7b-chat-norwegian    0.1080       0.0114   \n",
       "7               bineric/NorskGPT-Llama3-8b    0.1687       0.0151   \n",
       "8              bineric/NorskGPT-Mistral-7b    0.3050       0.0091   \n",
       "17                      google/gemma-2-27b    0.1507       0.0085   \n",
       "15                       google/gemma-2-2b    0.1643       0.0100   \n",
       "16                       google/gemma-2-9b    0.2080       0.0131   \n",
       "18              meta-llama/Meta-Llama-3-8B    0.1623       0.0135   \n",
       "10            meta-llama/Meta-Llama-3.1-8B    0.1707       0.0143   \n",
       "9                mistralai/Mistral-7B-v0.1    0.1287       0.0074   \n",
       "4            norallm/normistral-7b-scratch    0.1647       0.0109   \n",
       "3               norallm/normistral-7b-warm    0.1783       0.0129   \n",
       "6                 NorwAI/NorwAI-Mistral-7B    0.1683       0.0119   \n",
       "2      norallm/normistral-7b-warm-instruct    0.1830       0.0134   \n",
       "5        NorwAI/NorwAI-Mistral-7B-instruct    0.1717       0.0169   \n",
       "\n",
       "    mean_Macro_F1  mean_Macro_F1_ci  mean_MCC  mean_MCC_ci  \n",
       "14         0.5056            0.0154    0.5427       0.0213  \n",
       "12         0.3262            0.0150    0.3325       0.0187  \n",
       "13         0.5350            0.0150    0.5513       0.0191  \n",
       "22         0.0612            0.0085   -0.0069       0.0136  \n",
       "21         0.0269            0.0041    0.0008       0.0132  \n",
       "19         0.2644            0.0123    0.2538       0.0167  \n",
       "11         0.2180            0.0136    0.1638       0.0193  \n",
       "20         0.1733            0.0181    0.0886       0.0233  \n",
       "1          0.1979            0.0110    0.1459       0.0205  \n",
       "0          0.0869            0.0129    0.0280       0.0151  \n",
       "7          0.1514            0.0150    0.0614       0.0190  \n",
       "8          0.2689            0.0105    0.2254       0.0147  \n",
       "17         0.1397            0.0096    0.0608       0.0106  \n",
       "15         0.1308            0.0102    0.0498       0.0134  \n",
       "16         0.1702            0.0120    0.0751       0.0141  \n",
       "18         0.1416            0.0118    0.0338       0.0157  \n",
       "10         0.1448            0.0149    0.0436       0.0170  \n",
       "9          0.1031            0.0073   -0.0020       0.0062  \n",
       "4          0.1389            0.0141    0.0199       0.0151  \n",
       "3          0.1376            0.0127    0.0231       0.0154  \n",
       "6          0.1255            0.0124    0.0122       0.0146  \n",
       "2          0.0972            0.0083    0.0131       0.0125  \n",
       "5          0.1355            0.0149    0.0258       0.0167  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_results = \"RUNS/agg_results_11_01_2025.xlsx\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(updated_results, index_col=0).drop(columns=[\"run\"]) \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mean_acc</th>\n",
       "      <th>mean_acc_ci</th>\n",
       "      <th>mean_Macro_F1</th>\n",
       "      <th>mean_Macro_F1_ci</th>\n",
       "      <th>mean_MCC</th>\n",
       "      <th>mean_MCC_ci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>google/gemma-2-27b-it</td>\n",
       "      <td>60.53</td>\n",
       "      <td>2.31</td>\n",
       "      <td>50.56</td>\n",
       "      <td>1.54</td>\n",
       "      <td>54.27</td>\n",
       "      <td>2.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>google/gemma-2-2b-it</td>\n",
       "      <td>43.53</td>\n",
       "      <td>2.15</td>\n",
       "      <td>32.62</td>\n",
       "      <td>1.50</td>\n",
       "      <td>33.25</td>\n",
       "      <td>1.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>google/gemma-2-9b-it</td>\n",
       "      <td>62.10</td>\n",
       "      <td>1.80</td>\n",
       "      <td>53.50</td>\n",
       "      <td>1.50</td>\n",
       "      <td>55.13</td>\n",
       "      <td>1.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>meta-llama/Llama-2-13b-chat-hf</td>\n",
       "      <td>8.93</td>\n",
       "      <td>0.77</td>\n",
       "      <td>6.12</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-0.69</td>\n",
       "      <td>1.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>meta-llama/Llama-2-7b-chat-hf</td>\n",
       "      <td>6.40</td>\n",
       "      <td>0.71</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>meta-llama/Meta-Llama-3-8B-Instruct</td>\n",
       "      <td>33.03</td>\n",
       "      <td>1.34</td>\n",
       "      <td>26.44</td>\n",
       "      <td>1.23</td>\n",
       "      <td>25.38</td>\n",
       "      <td>1.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>meta-llama/Meta-Llama-3.1-8B-Instruct</td>\n",
       "      <td>24.87</td>\n",
       "      <td>1.13</td>\n",
       "      <td>21.80</td>\n",
       "      <td>1.36</td>\n",
       "      <td>16.38</td>\n",
       "      <td>1.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.1</td>\n",
       "      <td>23.60</td>\n",
       "      <td>1.74</td>\n",
       "      <td>17.33</td>\n",
       "      <td>1.81</td>\n",
       "      <td>8.86</td>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RuterNorway/Llama-2-13b-chat-norwegian</td>\n",
       "      <td>23.27</td>\n",
       "      <td>1.98</td>\n",
       "      <td>19.79</td>\n",
       "      <td>1.10</td>\n",
       "      <td>14.59</td>\n",
       "      <td>2.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RuterNorway/Llama-2-7b-chat-norwegian</td>\n",
       "      <td>10.80</td>\n",
       "      <td>1.14</td>\n",
       "      <td>8.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>2.80</td>\n",
       "      <td>1.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bineric/NorskGPT-Llama3-8b</td>\n",
       "      <td>16.87</td>\n",
       "      <td>1.51</td>\n",
       "      <td>15.14</td>\n",
       "      <td>1.50</td>\n",
       "      <td>6.14</td>\n",
       "      <td>1.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bineric/NorskGPT-Mistral-7b</td>\n",
       "      <td>30.50</td>\n",
       "      <td>0.91</td>\n",
       "      <td>26.89</td>\n",
       "      <td>1.05</td>\n",
       "      <td>22.54</td>\n",
       "      <td>1.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>google/gemma-2-27b</td>\n",
       "      <td>15.07</td>\n",
       "      <td>0.85</td>\n",
       "      <td>13.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>6.08</td>\n",
       "      <td>1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>google/gemma-2-2b</td>\n",
       "      <td>16.43</td>\n",
       "      <td>1.00</td>\n",
       "      <td>13.08</td>\n",
       "      <td>1.02</td>\n",
       "      <td>4.98</td>\n",
       "      <td>1.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>google/gemma-2-9b</td>\n",
       "      <td>20.80</td>\n",
       "      <td>1.31</td>\n",
       "      <td>17.02</td>\n",
       "      <td>1.20</td>\n",
       "      <td>7.51</td>\n",
       "      <td>1.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>meta-llama/Meta-Llama-3-8B</td>\n",
       "      <td>16.23</td>\n",
       "      <td>1.35</td>\n",
       "      <td>14.16</td>\n",
       "      <td>1.18</td>\n",
       "      <td>3.38</td>\n",
       "      <td>1.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>meta-llama/Meta-Llama-3.1-8B</td>\n",
       "      <td>17.07</td>\n",
       "      <td>1.43</td>\n",
       "      <td>14.48</td>\n",
       "      <td>1.49</td>\n",
       "      <td>4.36</td>\n",
       "      <td>1.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mistralai/Mistral-7B-v0.1</td>\n",
       "      <td>12.87</td>\n",
       "      <td>0.74</td>\n",
       "      <td>10.31</td>\n",
       "      <td>0.73</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>norallm/normistral-7b-scratch</td>\n",
       "      <td>16.47</td>\n",
       "      <td>1.09</td>\n",
       "      <td>13.89</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.99</td>\n",
       "      <td>1.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>norallm/normistral-7b-warm</td>\n",
       "      <td>17.83</td>\n",
       "      <td>1.29</td>\n",
       "      <td>13.76</td>\n",
       "      <td>1.27</td>\n",
       "      <td>2.31</td>\n",
       "      <td>1.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NorwAI/NorwAI-Mistral-7B</td>\n",
       "      <td>16.83</td>\n",
       "      <td>1.19</td>\n",
       "      <td>12.55</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>norallm/normistral-7b-warm-instruct</td>\n",
       "      <td>18.30</td>\n",
       "      <td>1.34</td>\n",
       "      <td>9.72</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.31</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NorwAI/NorwAI-Mistral-7B-instruct</td>\n",
       "      <td>17.17</td>\n",
       "      <td>1.69</td>\n",
       "      <td>13.55</td>\n",
       "      <td>1.49</td>\n",
       "      <td>2.58</td>\n",
       "      <td>1.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     model  mean_acc  mean_acc_ci  \\\n",
       "14                   google/gemma-2-27b-it     60.53         2.31   \n",
       "12                    google/gemma-2-2b-it     43.53         2.15   \n",
       "13                    google/gemma-2-9b-it     62.10         1.80   \n",
       "22          meta-llama/Llama-2-13b-chat-hf      8.93         0.77   \n",
       "21           meta-llama/Llama-2-7b-chat-hf      6.40         0.71   \n",
       "19     meta-llama/Meta-Llama-3-8B-Instruct     33.03         1.34   \n",
       "11   meta-llama/Meta-Llama-3.1-8B-Instruct     24.87         1.13   \n",
       "20      mistralai/Mistral-7B-Instruct-v0.1     23.60         1.74   \n",
       "1   RuterNorway/Llama-2-13b-chat-norwegian     23.27         1.98   \n",
       "0    RuterNorway/Llama-2-7b-chat-norwegian     10.80         1.14   \n",
       "7               bineric/NorskGPT-Llama3-8b     16.87         1.51   \n",
       "8              bineric/NorskGPT-Mistral-7b     30.50         0.91   \n",
       "17                      google/gemma-2-27b     15.07         0.85   \n",
       "15                       google/gemma-2-2b     16.43         1.00   \n",
       "16                       google/gemma-2-9b     20.80         1.31   \n",
       "18              meta-llama/Meta-Llama-3-8B     16.23         1.35   \n",
       "10            meta-llama/Meta-Llama-3.1-8B     17.07         1.43   \n",
       "9                mistralai/Mistral-7B-v0.1     12.87         0.74   \n",
       "4            norallm/normistral-7b-scratch     16.47         1.09   \n",
       "3               norallm/normistral-7b-warm     17.83         1.29   \n",
       "6                 NorwAI/NorwAI-Mistral-7B     16.83         1.19   \n",
       "2      norallm/normistral-7b-warm-instruct     18.30         1.34   \n",
       "5        NorwAI/NorwAI-Mistral-7B-instruct     17.17         1.69   \n",
       "\n",
       "    mean_Macro_F1  mean_Macro_F1_ci  mean_MCC  mean_MCC_ci  \n",
       "14          50.56              1.54     54.27         2.13  \n",
       "12          32.62              1.50     33.25         1.87  \n",
       "13          53.50              1.50     55.13         1.91  \n",
       "22           6.12              0.85     -0.69         1.36  \n",
       "21           2.69              0.41      0.08         1.32  \n",
       "19          26.44              1.23     25.38         1.67  \n",
       "11          21.80              1.36     16.38         1.93  \n",
       "20          17.33              1.81      8.86         2.33  \n",
       "1           19.79              1.10     14.59         2.05  \n",
       "0            8.69              1.29      2.80         1.51  \n",
       "7           15.14              1.50      6.14         1.90  \n",
       "8           26.89              1.05     22.54         1.47  \n",
       "17          13.97              0.96      6.08         1.06  \n",
       "15          13.08              1.02      4.98         1.34  \n",
       "16          17.02              1.20      7.51         1.41  \n",
       "18          14.16              1.18      3.38         1.57  \n",
       "10          14.48              1.49      4.36         1.70  \n",
       "9           10.31              0.73     -0.20         0.62  \n",
       "4           13.89              1.41      1.99         1.51  \n",
       "3           13.76              1.27      2.31         1.54  \n",
       "6           12.55              1.24      1.22         1.46  \n",
       "2            9.72              0.83      1.31         1.25  \n",
       "5           13.55              1.49      2.58         1.67  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric = [col for col in df.columns if df[col].dtype in [\"float64\", \"int64\"]]\n",
    "df[numeric] = df[numeric].multiply(100).round(2)\n",
    "\n",
    "# for col in numeric:\n",
    "#     df[col] = df[col].apply(lambda x: f\"{x*100:.2f}\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>google/gemma-2-27b-it</td>\n",
       "      <td>60.53 ± 2.31</td>\n",
       "      <td>50.56 ± 1.54</td>\n",
       "      <td>54.27 ± 2.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>google/gemma-2-2b-it</td>\n",
       "      <td>43.53 ± 2.15</td>\n",
       "      <td>32.62 ± 1.50</td>\n",
       "      <td>33.25 ± 1.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>google/gemma-2-9b-it</td>\n",
       "      <td>62.10 ± 1.80</td>\n",
       "      <td>53.50 ± 1.50</td>\n",
       "      <td>55.13 ± 1.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>meta-llama/Llama-2-13b-chat-hf</td>\n",
       "      <td>8.93 ± 0.77</td>\n",
       "      <td>6.12 ± 0.85</td>\n",
       "      <td>-0.69 ± 1.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>meta-llama/Llama-2-7b-chat-hf</td>\n",
       "      <td>6.40 ± 0.71</td>\n",
       "      <td>2.69 ± 0.41</td>\n",
       "      <td>0.08 ± 1.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>meta-llama/Meta-Llama-3-8B-Instruct</td>\n",
       "      <td>33.03 ± 1.34</td>\n",
       "      <td>26.44 ± 1.23</td>\n",
       "      <td>25.38 ± 1.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>meta-llama/Meta-Llama-3.1-8B-Instruct</td>\n",
       "      <td>24.87 ± 1.13</td>\n",
       "      <td>21.80 ± 1.36</td>\n",
       "      <td>16.38 ± 1.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.1</td>\n",
       "      <td>23.60 ± 1.74</td>\n",
       "      <td>17.33 ± 1.81</td>\n",
       "      <td>8.86 ± 2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RuterNorway/Llama-2-13b-chat-norwegian</td>\n",
       "      <td>23.27 ± 1.98</td>\n",
       "      <td>19.79 ± 1.10</td>\n",
       "      <td>14.59 ± 2.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RuterNorway/Llama-2-7b-chat-norwegian</td>\n",
       "      <td>10.80 ± 1.14</td>\n",
       "      <td>8.69 ± 1.29</td>\n",
       "      <td>2.80 ± 1.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bineric/NorskGPT-Llama3-8b</td>\n",
       "      <td>16.87 ± 1.51</td>\n",
       "      <td>15.14 ± 1.50</td>\n",
       "      <td>6.14 ± 1.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bineric/NorskGPT-Mistral-7b</td>\n",
       "      <td>30.50 ± 0.91</td>\n",
       "      <td>26.89 ± 1.05</td>\n",
       "      <td>22.54 ± 1.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>google/gemma-2-27b</td>\n",
       "      <td>15.07 ± 0.85</td>\n",
       "      <td>13.97 ± 0.96</td>\n",
       "      <td>6.08 ± 1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>google/gemma-2-2b</td>\n",
       "      <td>16.43 ± 1.00</td>\n",
       "      <td>13.08 ± 1.02</td>\n",
       "      <td>4.98 ± 1.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>google/gemma-2-9b</td>\n",
       "      <td>20.80 ± 1.31</td>\n",
       "      <td>17.02 ± 1.20</td>\n",
       "      <td>7.51 ± 1.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>meta-llama/Meta-Llama-3-8B</td>\n",
       "      <td>16.23 ± 1.35</td>\n",
       "      <td>14.16 ± 1.18</td>\n",
       "      <td>3.38 ± 1.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>meta-llama/Meta-Llama-3.1-8B</td>\n",
       "      <td>17.07 ± 1.43</td>\n",
       "      <td>14.48 ± 1.49</td>\n",
       "      <td>4.36 ± 1.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mistralai/Mistral-7B-v0.1</td>\n",
       "      <td>12.87 ± 0.74</td>\n",
       "      <td>10.31 ± 0.73</td>\n",
       "      <td>-0.20 ± 0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>norallm/normistral-7b-scratch</td>\n",
       "      <td>16.47 ± 1.09</td>\n",
       "      <td>13.89 ± 1.41</td>\n",
       "      <td>1.99 ± 1.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>norallm/normistral-7b-warm</td>\n",
       "      <td>17.83 ± 1.29</td>\n",
       "      <td>13.76 ± 1.27</td>\n",
       "      <td>2.31 ± 1.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NorwAI/NorwAI-Mistral-7B</td>\n",
       "      <td>16.83 ± 1.19</td>\n",
       "      <td>12.55 ± 1.24</td>\n",
       "      <td>1.22 ± 1.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>norallm/normistral-7b-warm-instruct</td>\n",
       "      <td>18.30 ± 1.34</td>\n",
       "      <td>9.72 ± 0.83</td>\n",
       "      <td>1.31 ± 1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NorwAI/NorwAI-Mistral-7B-instruct</td>\n",
       "      <td>17.17 ± 1.69</td>\n",
       "      <td>13.55 ± 1.49</td>\n",
       "      <td>2.58 ± 1.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     model           Acc      Macro F1  \\\n",
       "14                   google/gemma-2-27b-it  60.53 ± 2.31  50.56 ± 1.54   \n",
       "12                    google/gemma-2-2b-it  43.53 ± 2.15  32.62 ± 1.50   \n",
       "13                    google/gemma-2-9b-it  62.10 ± 1.80  53.50 ± 1.50   \n",
       "22          meta-llama/Llama-2-13b-chat-hf   8.93 ± 0.77   6.12 ± 0.85   \n",
       "21           meta-llama/Llama-2-7b-chat-hf   6.40 ± 0.71   2.69 ± 0.41   \n",
       "19     meta-llama/Meta-Llama-3-8B-Instruct  33.03 ± 1.34  26.44 ± 1.23   \n",
       "11   meta-llama/Meta-Llama-3.1-8B-Instruct  24.87 ± 1.13  21.80 ± 1.36   \n",
       "20      mistralai/Mistral-7B-Instruct-v0.1  23.60 ± 1.74  17.33 ± 1.81   \n",
       "1   RuterNorway/Llama-2-13b-chat-norwegian  23.27 ± 1.98  19.79 ± 1.10   \n",
       "0    RuterNorway/Llama-2-7b-chat-norwegian  10.80 ± 1.14   8.69 ± 1.29   \n",
       "7               bineric/NorskGPT-Llama3-8b  16.87 ± 1.51  15.14 ± 1.50   \n",
       "8              bineric/NorskGPT-Mistral-7b  30.50 ± 0.91  26.89 ± 1.05   \n",
       "17                      google/gemma-2-27b  15.07 ± 0.85  13.97 ± 0.96   \n",
       "15                       google/gemma-2-2b  16.43 ± 1.00  13.08 ± 1.02   \n",
       "16                       google/gemma-2-9b  20.80 ± 1.31  17.02 ± 1.20   \n",
       "18              meta-llama/Meta-Llama-3-8B  16.23 ± 1.35  14.16 ± 1.18   \n",
       "10            meta-llama/Meta-Llama-3.1-8B  17.07 ± 1.43  14.48 ± 1.49   \n",
       "9                mistralai/Mistral-7B-v0.1  12.87 ± 0.74  10.31 ± 0.73   \n",
       "4            norallm/normistral-7b-scratch  16.47 ± 1.09  13.89 ± 1.41   \n",
       "3               norallm/normistral-7b-warm  17.83 ± 1.29  13.76 ± 1.27   \n",
       "6                 NorwAI/NorwAI-Mistral-7B  16.83 ± 1.19  12.55 ± 1.24   \n",
       "2      norallm/normistral-7b-warm-instruct  18.30 ± 1.34   9.72 ± 0.83   \n",
       "5        NorwAI/NorwAI-Mistral-7B-instruct  17.17 ± 1.69  13.55 ± 1.49   \n",
       "\n",
       "             MCC  \n",
       "14  54.27 ± 2.13  \n",
       "12  33.25 ± 1.87  \n",
       "13  55.13 ± 1.91  \n",
       "22  -0.69 ± 1.36  \n",
       "21   0.08 ± 1.32  \n",
       "19  25.38 ± 1.67  \n",
       "11  16.38 ± 1.93  \n",
       "20   8.86 ± 2.33  \n",
       "1   14.59 ± 2.05  \n",
       "0    2.80 ± 1.51  \n",
       "7    6.14 ± 1.90  \n",
       "8   22.54 ± 1.47  \n",
       "17   6.08 ± 1.06  \n",
       "15   4.98 ± 1.34  \n",
       "16   7.51 ± 1.41  \n",
       "18   3.38 ± 1.57  \n",
       "10   4.36 ± 1.70  \n",
       "9   -0.20 ± 0.62  \n",
       "4    1.99 ± 1.51  \n",
       "3    2.31 ± 1.54  \n",
       "6    1.22 ± 1.46  \n",
       "2    1.31 ± 1.25  \n",
       "5    2.58 ± 1.67  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we combine them into +/- values\n",
    "col_groups = {\n",
    "    \"mean_acc\": \"mean_acc_ci\",\n",
    "    \"mean_Macro_F1\": \"mean_Macro_F1_ci\",\n",
    "    \"mean_MCC\": \"mean_MCC_ci\",\n",
    "}\n",
    "combined_names = {\n",
    "    \"mean_acc\": \"Acc\",\n",
    "    \"mean_Macro_F1\": \"Macro F1\",\n",
    "    \"mean_MCC\": \"MCC\",\n",
    "}\n",
    "\n",
    "for col, ci in col_groups.items():\n",
    "    df[combined_names[col]] = df[col].apply(lambda x: f\"{x:.2f}\") + \" ± \" + df[ci].apply(lambda x: f\"{x:.2f}\")\n",
    "    df = df.drop(columns=[col, ci])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>NorNE-nb</th>\n",
       "      <th>NoReC</th>\n",
       "      <th>NorQuAD</th>\n",
       "      <th>HellaSwag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>google/gemma-2-27b-it</td>\n",
       "      <td>56.75 ± 3.04</td>\n",
       "      <td>78.63 ± 0.96</td>\n",
       "      <td>73.41 ± 1.61</td>\n",
       "      <td>77.92 ± 1.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>google/gemma-2-9b-it</td>\n",
       "      <td>44.91 ± 3.62</td>\n",
       "      <td>73.45 ± 0.94</td>\n",
       "      <td>70.14 ± 1.53</td>\n",
       "      <td>75.79 ± 1.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>google/gemma-2-27b</td>\n",
       "      <td>43.06 ± 1.89</td>\n",
       "      <td>76.14 ± 1.68</td>\n",
       "      <td>80.21 ± 4.49</td>\n",
       "      <td>63.55 ± 4.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>google/gemma-2-9b</td>\n",
       "      <td>34.62 ± 1.80</td>\n",
       "      <td>75.53 ± 0.73</td>\n",
       "      <td>72.99 ± 3.16</td>\n",
       "      <td>63.52 ± 3.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bineric/NorskGPT-Llama3-8b</td>\n",
       "      <td>60.25 ± 3.14</td>\n",
       "      <td>61.42 ± 3.56</td>\n",
       "      <td>74.57 ± 2.20</td>\n",
       "      <td>59.11 ± 2.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>meta-llama/Meta-Llama-3.1-8B-Instruct</td>\n",
       "      <td>71.87 ± 0.97</td>\n",
       "      <td>71.58 ± 0.90</td>\n",
       "      <td>70.96 ± 3.00</td>\n",
       "      <td>54.03 ± 0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>meta-llama/Meta-Llama-3.1-8B</td>\n",
       "      <td>53.50 ± 3.27</td>\n",
       "      <td>68.71 ± 1.01</td>\n",
       "      <td>75.98 ± 2.62</td>\n",
       "      <td>46.84 ± 1.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bineric/NorskGPT-Mistral-7b</td>\n",
       "      <td>47.72 ± 3.74</td>\n",
       "      <td>70.81 ± 1.30</td>\n",
       "      <td>74.38 ± 3.92</td>\n",
       "      <td>60.59 ± 1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>meta-llama/Meta-Llama-3-8B-Instruct</td>\n",
       "      <td>65.57 ± 2.39</td>\n",
       "      <td>65.69 ± 3.50</td>\n",
       "      <td>69.90 ± 3.17</td>\n",
       "      <td>45.85 ± 1.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>meta-llama/Meta-Llama-3-8B</td>\n",
       "      <td>47.65 ± 2.94</td>\n",
       "      <td>66.15 ± 1.44</td>\n",
       "      <td>74.98 ± 3.70</td>\n",
       "      <td>42.47 ± 2.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mistralai/Mistral-7B-v0.1</td>\n",
       "      <td>43.55 ± 2.21</td>\n",
       "      <td>64.53 ± 3.71</td>\n",
       "      <td>70.86 ± 2.79</td>\n",
       "      <td>32.43 ± 2.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>meta-llama/Llama-2-13b-chat-hf</td>\n",
       "      <td>40.40 ± 2.79</td>\n",
       "      <td>57.45 ± 3.77</td>\n",
       "      <td>69.24 ± 2.68</td>\n",
       "      <td>41.00 ± 1.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RuterNorway/Llama-2-13b-chat-norwegian</td>\n",
       "      <td>47.74 ± 2.83</td>\n",
       "      <td>58.47 ± 3.79</td>\n",
       "      <td>65.76 ± 3.07</td>\n",
       "      <td>41.29 ± 1.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>google/gemma-2-2b-it</td>\n",
       "      <td>28.77 ± 2.22</td>\n",
       "      <td>63.18 ± 1.91</td>\n",
       "      <td>63.84 ± 1.50</td>\n",
       "      <td>49.42 ± 0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.1</td>\n",
       "      <td>34.52 ± 1.17</td>\n",
       "      <td>60.88 ± 1.36</td>\n",
       "      <td>63.67 ± 2.98</td>\n",
       "      <td>35.89 ± 1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>meta-llama/Llama-2-7b-chat-hf</td>\n",
       "      <td>38.59 ± 2.84</td>\n",
       "      <td>57.09 ± 3.80</td>\n",
       "      <td>61.99 ± 2.34</td>\n",
       "      <td>31.84 ± 1.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NorwAI/NorwAI-Mistral-7B</td>\n",
       "      <td>20.45 ± 2.65</td>\n",
       "      <td>65.98 ± 2.95</td>\n",
       "      <td>68.04 ± 5.37</td>\n",
       "      <td>27.82 ± 1.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>norallm/normistral-7b-warm-instruct</td>\n",
       "      <td>31.87 ± 1.92</td>\n",
       "      <td>43.91 ± 2.51</td>\n",
       "      <td>59.27 ± 1.53</td>\n",
       "      <td>29.64 ± 1.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>google/gemma-2-2b</td>\n",
       "      <td>21.28 ± 2.58</td>\n",
       "      <td>47.91 ± 2.11</td>\n",
       "      <td>63.31 ± 3.73</td>\n",
       "      <td>28.89 ± 1.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>norallm/normistral-7b-warm</td>\n",
       "      <td>31.45 ± 1.88</td>\n",
       "      <td>45.30 ± 3.46</td>\n",
       "      <td>61.85 ± 3.07</td>\n",
       "      <td>25.00 ± 0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NorwAI/NorwAI-Mistral-7B-instruct</td>\n",
       "      <td>24.26 ± 1.41</td>\n",
       "      <td>64.33 ± 2.80</td>\n",
       "      <td>29.01 ± 1.18</td>\n",
       "      <td>25.82 ± 0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>norallm/normistral-7b-scratch</td>\n",
       "      <td>15.44 ± 5.52</td>\n",
       "      <td>36.85 ± 2.01</td>\n",
       "      <td>38.93 ± 2.59</td>\n",
       "      <td>24.84 ± 0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RuterNorway/Llama-2-7b-chat-norwegian</td>\n",
       "      <td>20.44 ± 2.47</td>\n",
       "      <td>23.50 ± 3.03</td>\n",
       "      <td>50.11 ± 1.80</td>\n",
       "      <td>24.48 ± 0.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     model       NorNE-nb          NoReC  \\\n",
       "0                    google/gemma-2-27b-it   56.75 ± 3.04   78.63 ± 0.96   \n",
       "1                     google/gemma-2-9b-it   44.91 ± 3.62   73.45 ± 0.94   \n",
       "2                       google/gemma-2-27b   43.06 ± 1.89   76.14 ± 1.68   \n",
       "3                        google/gemma-2-9b   34.62 ± 1.80   75.53 ± 0.73   \n",
       "4               bineric/NorskGPT-Llama3-8b   60.25 ± 3.14   61.42 ± 3.56   \n",
       "5    meta-llama/Meta-Llama-3.1-8B-Instruct   71.87 ± 0.97   71.58 ± 0.90   \n",
       "6             meta-llama/Meta-Llama-3.1-8B   53.50 ± 3.27   68.71 ± 1.01   \n",
       "7              bineric/NorskGPT-Mistral-7b   47.72 ± 3.74   70.81 ± 1.30   \n",
       "8      meta-llama/Meta-Llama-3-8B-Instruct   65.57 ± 2.39   65.69 ± 3.50   \n",
       "9               meta-llama/Meta-Llama-3-8B   47.65 ± 2.94   66.15 ± 1.44   \n",
       "10               mistralai/Mistral-7B-v0.1   43.55 ± 2.21   64.53 ± 3.71   \n",
       "11          meta-llama/Llama-2-13b-chat-hf   40.40 ± 2.79   57.45 ± 3.77   \n",
       "12  RuterNorway/Llama-2-13b-chat-norwegian   47.74 ± 2.83   58.47 ± 3.79   \n",
       "13                    google/gemma-2-2b-it   28.77 ± 2.22   63.18 ± 1.91   \n",
       "14      mistralai/Mistral-7B-Instruct-v0.1   34.52 ± 1.17   60.88 ± 1.36   \n",
       "15           meta-llama/Llama-2-7b-chat-hf   38.59 ± 2.84   57.09 ± 3.80   \n",
       "16                NorwAI/NorwAI-Mistral-7B   20.45 ± 2.65   65.98 ± 2.95   \n",
       "17     norallm/normistral-7b-warm-instruct   31.87 ± 1.92   43.91 ± 2.51   \n",
       "18                       google/gemma-2-2b   21.28 ± 2.58   47.91 ± 2.11   \n",
       "19              norallm/normistral-7b-warm   31.45 ± 1.88   45.30 ± 3.46   \n",
       "20       NorwAI/NorwAI-Mistral-7B-instruct   24.26 ± 1.41   64.33 ± 2.80   \n",
       "21           norallm/normistral-7b-scratch   15.44 ± 5.52   36.85 ± 2.01   \n",
       "22   RuterNorway/Llama-2-7b-chat-norwegian   20.44 ± 2.47   23.50 ± 3.03   \n",
       "\n",
       "          NorQuAD      HellaSwag  \n",
       "0    73.41 ± 1.61   77.92 ± 1.72  \n",
       "1    70.14 ± 1.53   75.79 ± 1.47  \n",
       "2    80.21 ± 4.49   63.55 ± 4.76  \n",
       "3    72.99 ± 3.16   63.52 ± 3.49  \n",
       "4    74.57 ± 2.20   59.11 ± 2.44  \n",
       "5    70.96 ± 3.00   54.03 ± 0.82  \n",
       "6    75.98 ± 2.62   46.84 ± 1.59  \n",
       "7    74.38 ± 3.92   60.59 ± 1.18  \n",
       "8    69.90 ± 3.17   45.85 ± 1.93  \n",
       "9    74.98 ± 3.70   42.47 ± 2.74  \n",
       "10   70.86 ± 2.79   32.43 ± 2.67  \n",
       "11   69.24 ± 2.68   41.00 ± 1.40  \n",
       "12   65.76 ± 3.07   41.29 ± 1.19  \n",
       "13   63.84 ± 1.50   49.42 ± 0.79  \n",
       "14   63.67 ± 2.98   35.89 ± 1.06  \n",
       "15   61.99 ± 2.34   31.84 ± 1.05  \n",
       "16   68.04 ± 5.37   27.82 ± 1.56  \n",
       "17   59.27 ± 1.53   29.64 ± 1.49  \n",
       "18   63.31 ± 3.73   28.89 ± 1.54  \n",
       "19   61.85 ± 3.07   25.00 ± 0.83  \n",
       "20   29.01 ± 1.18   25.82 ± 0.79  \n",
       "21   38.93 ± 2.59   24.84 ± 0.71  \n",
       "22   50.11 ± 1.80   24.48 ± 0.70  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from util import load_scandeval\n",
    "\n",
    "sdval = load_scandeval(date=\"09-10-2024\")\n",
    "sdval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>MCC</th>\n",
       "      <th>NorNE-nb</th>\n",
       "      <th>NoReC</th>\n",
       "      <th>NorQuAD</th>\n",
       "      <th>HellaSwag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>google/gemma-2-27b-it</td>\n",
       "      <td>60.53 ± 2.31</td>\n",
       "      <td>50.56 ± 1.54</td>\n",
       "      <td>54.27 ± 2.13</td>\n",
       "      <td>56.75 ± 3.04</td>\n",
       "      <td>78.63 ± 0.96</td>\n",
       "      <td>73.41 ± 1.61</td>\n",
       "      <td>77.92 ± 1.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>google/gemma-2-2b-it</td>\n",
       "      <td>43.53 ± 2.15</td>\n",
       "      <td>32.62 ± 1.50</td>\n",
       "      <td>33.25 ± 1.87</td>\n",
       "      <td>28.77 ± 2.22</td>\n",
       "      <td>63.18 ± 1.91</td>\n",
       "      <td>63.84 ± 1.50</td>\n",
       "      <td>49.42 ± 0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>google/gemma-2-9b-it</td>\n",
       "      <td>62.10 ± 1.80</td>\n",
       "      <td>53.50 ± 1.50</td>\n",
       "      <td>55.13 ± 1.91</td>\n",
       "      <td>44.91 ± 3.62</td>\n",
       "      <td>73.45 ± 0.94</td>\n",
       "      <td>70.14 ± 1.53</td>\n",
       "      <td>75.79 ± 1.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>meta-llama/Llama-2-13b-chat-hf</td>\n",
       "      <td>8.93 ± 0.77</td>\n",
       "      <td>6.12 ± 0.85</td>\n",
       "      <td>-0.69 ± 1.36</td>\n",
       "      <td>40.40 ± 2.79</td>\n",
       "      <td>57.45 ± 3.77</td>\n",
       "      <td>69.24 ± 2.68</td>\n",
       "      <td>41.00 ± 1.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>meta-llama/Llama-2-7b-chat-hf</td>\n",
       "      <td>6.40 ± 0.71</td>\n",
       "      <td>2.69 ± 0.41</td>\n",
       "      <td>0.08 ± 1.32</td>\n",
       "      <td>38.59 ± 2.84</td>\n",
       "      <td>57.09 ± 3.80</td>\n",
       "      <td>61.99 ± 2.34</td>\n",
       "      <td>31.84 ± 1.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>meta-llama/Meta-Llama-3-8B-Instruct</td>\n",
       "      <td>33.03 ± 1.34</td>\n",
       "      <td>26.44 ± 1.23</td>\n",
       "      <td>25.38 ± 1.67</td>\n",
       "      <td>65.57 ± 2.39</td>\n",
       "      <td>65.69 ± 3.50</td>\n",
       "      <td>69.90 ± 3.17</td>\n",
       "      <td>45.85 ± 1.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>meta-llama/Meta-Llama-3.1-8B-Instruct</td>\n",
       "      <td>24.87 ± 1.13</td>\n",
       "      <td>21.80 ± 1.36</td>\n",
       "      <td>16.38 ± 1.93</td>\n",
       "      <td>71.87 ± 0.97</td>\n",
       "      <td>71.58 ± 0.90</td>\n",
       "      <td>70.96 ± 3.00</td>\n",
       "      <td>54.03 ± 0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.1</td>\n",
       "      <td>23.60 ± 1.74</td>\n",
       "      <td>17.33 ± 1.81</td>\n",
       "      <td>8.86 ± 2.33</td>\n",
       "      <td>34.52 ± 1.17</td>\n",
       "      <td>60.88 ± 1.36</td>\n",
       "      <td>63.67 ± 2.98</td>\n",
       "      <td>35.89 ± 1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RuterNorway/Llama-2-13b-chat-norwegian</td>\n",
       "      <td>23.27 ± 1.98</td>\n",
       "      <td>19.79 ± 1.10</td>\n",
       "      <td>14.59 ± 2.05</td>\n",
       "      <td>47.74 ± 2.83</td>\n",
       "      <td>58.47 ± 3.79</td>\n",
       "      <td>65.76 ± 3.07</td>\n",
       "      <td>41.29 ± 1.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RuterNorway/Llama-2-7b-chat-norwegian</td>\n",
       "      <td>10.80 ± 1.14</td>\n",
       "      <td>8.69 ± 1.29</td>\n",
       "      <td>2.80 ± 1.51</td>\n",
       "      <td>20.44 ± 2.47</td>\n",
       "      <td>23.50 ± 3.03</td>\n",
       "      <td>50.11 ± 1.80</td>\n",
       "      <td>24.48 ± 0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bineric/NorskGPT-Llama3-8b</td>\n",
       "      <td>16.87 ± 1.51</td>\n",
       "      <td>15.14 ± 1.50</td>\n",
       "      <td>6.14 ± 1.90</td>\n",
       "      <td>60.25 ± 3.14</td>\n",
       "      <td>61.42 ± 3.56</td>\n",
       "      <td>74.57 ± 2.20</td>\n",
       "      <td>59.11 ± 2.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bineric/NorskGPT-Mistral-7b</td>\n",
       "      <td>30.50 ± 0.91</td>\n",
       "      <td>26.89 ± 1.05</td>\n",
       "      <td>22.54 ± 1.47</td>\n",
       "      <td>47.72 ± 3.74</td>\n",
       "      <td>70.81 ± 1.30</td>\n",
       "      <td>74.38 ± 3.92</td>\n",
       "      <td>60.59 ± 1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>google/gemma-2-27b</td>\n",
       "      <td>15.07 ± 0.85</td>\n",
       "      <td>13.97 ± 0.96</td>\n",
       "      <td>6.08 ± 1.06</td>\n",
       "      <td>43.06 ± 1.89</td>\n",
       "      <td>76.14 ± 1.68</td>\n",
       "      <td>80.21 ± 4.49</td>\n",
       "      <td>63.55 ± 4.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>google/gemma-2-2b</td>\n",
       "      <td>16.43 ± 1.00</td>\n",
       "      <td>13.08 ± 1.02</td>\n",
       "      <td>4.98 ± 1.34</td>\n",
       "      <td>21.28 ± 2.58</td>\n",
       "      <td>47.91 ± 2.11</td>\n",
       "      <td>63.31 ± 3.73</td>\n",
       "      <td>28.89 ± 1.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>google/gemma-2-9b</td>\n",
       "      <td>20.80 ± 1.31</td>\n",
       "      <td>17.02 ± 1.20</td>\n",
       "      <td>7.51 ± 1.41</td>\n",
       "      <td>34.62 ± 1.80</td>\n",
       "      <td>75.53 ± 0.73</td>\n",
       "      <td>72.99 ± 3.16</td>\n",
       "      <td>63.52 ± 3.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>meta-llama/Meta-Llama-3-8B</td>\n",
       "      <td>16.23 ± 1.35</td>\n",
       "      <td>14.16 ± 1.18</td>\n",
       "      <td>3.38 ± 1.57</td>\n",
       "      <td>47.65 ± 2.94</td>\n",
       "      <td>66.15 ± 1.44</td>\n",
       "      <td>74.98 ± 3.70</td>\n",
       "      <td>42.47 ± 2.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>meta-llama/Meta-Llama-3.1-8B</td>\n",
       "      <td>17.07 ± 1.43</td>\n",
       "      <td>14.48 ± 1.49</td>\n",
       "      <td>4.36 ± 1.70</td>\n",
       "      <td>53.50 ± 3.27</td>\n",
       "      <td>68.71 ± 1.01</td>\n",
       "      <td>75.98 ± 2.62</td>\n",
       "      <td>46.84 ± 1.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mistralai/Mistral-7B-v0.1</td>\n",
       "      <td>12.87 ± 0.74</td>\n",
       "      <td>10.31 ± 0.73</td>\n",
       "      <td>-0.20 ± 0.62</td>\n",
       "      <td>43.55 ± 2.21</td>\n",
       "      <td>64.53 ± 3.71</td>\n",
       "      <td>70.86 ± 2.79</td>\n",
       "      <td>32.43 ± 2.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>norallm/normistral-7b-scratch</td>\n",
       "      <td>16.47 ± 1.09</td>\n",
       "      <td>13.89 ± 1.41</td>\n",
       "      <td>1.99 ± 1.51</td>\n",
       "      <td>15.44 ± 5.52</td>\n",
       "      <td>36.85 ± 2.01</td>\n",
       "      <td>38.93 ± 2.59</td>\n",
       "      <td>24.84 ± 0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>norallm/normistral-7b-warm</td>\n",
       "      <td>17.83 ± 1.29</td>\n",
       "      <td>13.76 ± 1.27</td>\n",
       "      <td>2.31 ± 1.54</td>\n",
       "      <td>31.45 ± 1.88</td>\n",
       "      <td>45.30 ± 3.46</td>\n",
       "      <td>61.85 ± 3.07</td>\n",
       "      <td>25.00 ± 0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NorwAI/NorwAI-Mistral-7B</td>\n",
       "      <td>16.83 ± 1.19</td>\n",
       "      <td>12.55 ± 1.24</td>\n",
       "      <td>1.22 ± 1.46</td>\n",
       "      <td>20.45 ± 2.65</td>\n",
       "      <td>65.98 ± 2.95</td>\n",
       "      <td>68.04 ± 5.37</td>\n",
       "      <td>27.82 ± 1.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>norallm/normistral-7b-warm-instruct</td>\n",
       "      <td>18.30 ± 1.34</td>\n",
       "      <td>9.72 ± 0.83</td>\n",
       "      <td>1.31 ± 1.25</td>\n",
       "      <td>31.87 ± 1.92</td>\n",
       "      <td>43.91 ± 2.51</td>\n",
       "      <td>59.27 ± 1.53</td>\n",
       "      <td>29.64 ± 1.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NorwAI/NorwAI-Mistral-7B-instruct</td>\n",
       "      <td>17.17 ± 1.69</td>\n",
       "      <td>13.55 ± 1.49</td>\n",
       "      <td>2.58 ± 1.67</td>\n",
       "      <td>24.26 ± 1.41</td>\n",
       "      <td>64.33 ± 2.80</td>\n",
       "      <td>29.01 ± 1.18</td>\n",
       "      <td>25.82 ± 0.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     model           Acc      Macro F1  \\\n",
       "14                   google/gemma-2-27b-it  60.53 ± 2.31  50.56 ± 1.54   \n",
       "12                    google/gemma-2-2b-it  43.53 ± 2.15  32.62 ± 1.50   \n",
       "13                    google/gemma-2-9b-it  62.10 ± 1.80  53.50 ± 1.50   \n",
       "22          meta-llama/Llama-2-13b-chat-hf   8.93 ± 0.77   6.12 ± 0.85   \n",
       "21           meta-llama/Llama-2-7b-chat-hf   6.40 ± 0.71   2.69 ± 0.41   \n",
       "19     meta-llama/Meta-Llama-3-8B-Instruct  33.03 ± 1.34  26.44 ± 1.23   \n",
       "11   meta-llama/Meta-Llama-3.1-8B-Instruct  24.87 ± 1.13  21.80 ± 1.36   \n",
       "20      mistralai/Mistral-7B-Instruct-v0.1  23.60 ± 1.74  17.33 ± 1.81   \n",
       "1   RuterNorway/Llama-2-13b-chat-norwegian  23.27 ± 1.98  19.79 ± 1.10   \n",
       "0    RuterNorway/Llama-2-7b-chat-norwegian  10.80 ± 1.14   8.69 ± 1.29   \n",
       "7               bineric/NorskGPT-Llama3-8b  16.87 ± 1.51  15.14 ± 1.50   \n",
       "8              bineric/NorskGPT-Mistral-7b  30.50 ± 0.91  26.89 ± 1.05   \n",
       "17                      google/gemma-2-27b  15.07 ± 0.85  13.97 ± 0.96   \n",
       "15                       google/gemma-2-2b  16.43 ± 1.00  13.08 ± 1.02   \n",
       "16                       google/gemma-2-9b  20.80 ± 1.31  17.02 ± 1.20   \n",
       "18              meta-llama/Meta-Llama-3-8B  16.23 ± 1.35  14.16 ± 1.18   \n",
       "10            meta-llama/Meta-Llama-3.1-8B  17.07 ± 1.43  14.48 ± 1.49   \n",
       "9                mistralai/Mistral-7B-v0.1  12.87 ± 0.74  10.31 ± 0.73   \n",
       "4            norallm/normistral-7b-scratch  16.47 ± 1.09  13.89 ± 1.41   \n",
       "3               norallm/normistral-7b-warm  17.83 ± 1.29  13.76 ± 1.27   \n",
       "6                 NorwAI/NorwAI-Mistral-7B  16.83 ± 1.19  12.55 ± 1.24   \n",
       "2      norallm/normistral-7b-warm-instruct  18.30 ± 1.34   9.72 ± 0.83   \n",
       "5        NorwAI/NorwAI-Mistral-7B-instruct  17.17 ± 1.69  13.55 ± 1.49   \n",
       "\n",
       "             MCC       NorNE-nb          NoReC        NorQuAD      HellaSwag  \n",
       "14  54.27 ± 2.13   56.75 ± 3.04   78.63 ± 0.96   73.41 ± 1.61   77.92 ± 1.72  \n",
       "12  33.25 ± 1.87   28.77 ± 2.22   63.18 ± 1.91   63.84 ± 1.50   49.42 ± 0.79  \n",
       "13  55.13 ± 1.91   44.91 ± 3.62   73.45 ± 0.94   70.14 ± 1.53   75.79 ± 1.47  \n",
       "22  -0.69 ± 1.36   40.40 ± 2.79   57.45 ± 3.77   69.24 ± 2.68   41.00 ± 1.40  \n",
       "21   0.08 ± 1.32   38.59 ± 2.84   57.09 ± 3.80   61.99 ± 2.34   31.84 ± 1.05  \n",
       "19  25.38 ± 1.67   65.57 ± 2.39   65.69 ± 3.50   69.90 ± 3.17   45.85 ± 1.93  \n",
       "11  16.38 ± 1.93   71.87 ± 0.97   71.58 ± 0.90   70.96 ± 3.00   54.03 ± 0.82  \n",
       "20   8.86 ± 2.33   34.52 ± 1.17   60.88 ± 1.36   63.67 ± 2.98   35.89 ± 1.06  \n",
       "1   14.59 ± 2.05   47.74 ± 2.83   58.47 ± 3.79   65.76 ± 3.07   41.29 ± 1.19  \n",
       "0    2.80 ± 1.51   20.44 ± 2.47   23.50 ± 3.03   50.11 ± 1.80   24.48 ± 0.70  \n",
       "7    6.14 ± 1.90   60.25 ± 3.14   61.42 ± 3.56   74.57 ± 2.20   59.11 ± 2.44  \n",
       "8   22.54 ± 1.47   47.72 ± 3.74   70.81 ± 1.30   74.38 ± 3.92   60.59 ± 1.18  \n",
       "17   6.08 ± 1.06   43.06 ± 1.89   76.14 ± 1.68   80.21 ± 4.49   63.55 ± 4.76  \n",
       "15   4.98 ± 1.34   21.28 ± 2.58   47.91 ± 2.11   63.31 ± 3.73   28.89 ± 1.54  \n",
       "16   7.51 ± 1.41   34.62 ± 1.80   75.53 ± 0.73   72.99 ± 3.16   63.52 ± 3.49  \n",
       "18   3.38 ± 1.57   47.65 ± 2.94   66.15 ± 1.44   74.98 ± 3.70   42.47 ± 2.74  \n",
       "10   4.36 ± 1.70   53.50 ± 3.27   68.71 ± 1.01   75.98 ± 2.62   46.84 ± 1.59  \n",
       "9   -0.20 ± 0.62   43.55 ± 2.21   64.53 ± 3.71   70.86 ± 2.79   32.43 ± 2.67  \n",
       "4    1.99 ± 1.51   15.44 ± 5.52   36.85 ± 2.01   38.93 ± 2.59   24.84 ± 0.71  \n",
       "3    2.31 ± 1.54   31.45 ± 1.88   45.30 ± 3.46   61.85 ± 3.07   25.00 ± 0.83  \n",
       "6    1.22 ± 1.46   20.45 ± 2.65   65.98 ± 2.95   68.04 ± 5.37   27.82 ± 1.56  \n",
       "2    1.31 ± 1.25   31.87 ± 1.92   43.91 ± 2.51   59.27 ± 1.53   29.64 ± 1.49  \n",
       "5    2.58 ± 1.67   24.26 ± 1.41   64.33 ± 2.80   29.01 ± 1.18   25.82 ± 0.79  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join on model:\n",
    "df = df.join(sdval.set_index(\"model\"), on=\"model\", how=\"left\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>MCC</th>\n",
       "      <th>NorNE-nb</th>\n",
       "      <th>NoReC</th>\n",
       "      <th>NorQuAD</th>\n",
       "      <th>HellaSwag</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>google/gemma-2-27b-it</td>\n",
       "      <td>60.53 ± 2.31</td>\n",
       "      <td>50.56 ± 1.54</td>\n",
       "      <td>54.27 ± 2.13</td>\n",
       "      <td>56.75 ± 3.04</td>\n",
       "      <td>78.63 ± 0.96</td>\n",
       "      <td>73.41 ± 1.61</td>\n",
       "      <td>77.92 ± 1.72</td>\n",
       "      <td>IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>google/gemma-2-2b-it</td>\n",
       "      <td>43.53 ± 2.15</td>\n",
       "      <td>32.62 ± 1.50</td>\n",
       "      <td>33.25 ± 1.87</td>\n",
       "      <td>28.77 ± 2.22</td>\n",
       "      <td>63.18 ± 1.91</td>\n",
       "      <td>63.84 ± 1.50</td>\n",
       "      <td>49.42 ± 0.79</td>\n",
       "      <td>IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>google/gemma-2-9b-it</td>\n",
       "      <td>62.10 ± 1.80</td>\n",
       "      <td>53.50 ± 1.50</td>\n",
       "      <td>55.13 ± 1.91</td>\n",
       "      <td>44.91 ± 3.62</td>\n",
       "      <td>73.45 ± 0.94</td>\n",
       "      <td>70.14 ± 1.53</td>\n",
       "      <td>75.79 ± 1.47</td>\n",
       "      <td>IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>meta-llama/Llama-2-13b-chat-hf</td>\n",
       "      <td>8.93 ± 0.77</td>\n",
       "      <td>6.12 ± 0.85</td>\n",
       "      <td>-0.69 ± 1.36</td>\n",
       "      <td>40.40 ± 2.79</td>\n",
       "      <td>57.45 ± 3.77</td>\n",
       "      <td>69.24 ± 2.68</td>\n",
       "      <td>41.00 ± 1.40</td>\n",
       "      <td>IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>meta-llama/Llama-2-7b-chat-hf</td>\n",
       "      <td>6.40 ± 0.71</td>\n",
       "      <td>2.69 ± 0.41</td>\n",
       "      <td>0.08 ± 1.32</td>\n",
       "      <td>38.59 ± 2.84</td>\n",
       "      <td>57.09 ± 3.80</td>\n",
       "      <td>61.99 ± 2.34</td>\n",
       "      <td>31.84 ± 1.05</td>\n",
       "      <td>IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>meta-llama/Meta-Llama-3-8B-Instruct</td>\n",
       "      <td>33.03 ± 1.34</td>\n",
       "      <td>26.44 ± 1.23</td>\n",
       "      <td>25.38 ± 1.67</td>\n",
       "      <td>65.57 ± 2.39</td>\n",
       "      <td>65.69 ± 3.50</td>\n",
       "      <td>69.90 ± 3.17</td>\n",
       "      <td>45.85 ± 1.93</td>\n",
       "      <td>IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>meta-llama/Meta-Llama-3.1-8B-Instruct</td>\n",
       "      <td>24.87 ± 1.13</td>\n",
       "      <td>21.80 ± 1.36</td>\n",
       "      <td>16.38 ± 1.93</td>\n",
       "      <td>71.87 ± 0.97</td>\n",
       "      <td>71.58 ± 0.90</td>\n",
       "      <td>70.96 ± 3.00</td>\n",
       "      <td>54.03 ± 0.82</td>\n",
       "      <td>IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.1</td>\n",
       "      <td>23.60 ± 1.74</td>\n",
       "      <td>17.33 ± 1.81</td>\n",
       "      <td>8.86 ± 2.33</td>\n",
       "      <td>34.52 ± 1.17</td>\n",
       "      <td>60.88 ± 1.36</td>\n",
       "      <td>63.67 ± 2.98</td>\n",
       "      <td>35.89 ± 1.06</td>\n",
       "      <td>IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RuterNorway/Llama-2-13b-chat-norwegian</td>\n",
       "      <td>23.27 ± 1.98</td>\n",
       "      <td>19.79 ± 1.10</td>\n",
       "      <td>14.59 ± 2.05</td>\n",
       "      <td>47.74 ± 2.83</td>\n",
       "      <td>58.47 ± 3.79</td>\n",
       "      <td>65.76 ± 3.07</td>\n",
       "      <td>41.29 ± 1.19</td>\n",
       "      <td>IT + FNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RuterNorway/Llama-2-7b-chat-norwegian</td>\n",
       "      <td>10.80 ± 1.14</td>\n",
       "      <td>8.69 ± 1.29</td>\n",
       "      <td>2.80 ± 1.51</td>\n",
       "      <td>20.44 ± 2.47</td>\n",
       "      <td>23.50 ± 3.03</td>\n",
       "      <td>50.11 ± 1.80</td>\n",
       "      <td>24.48 ± 0.70</td>\n",
       "      <td>IT + FNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bineric/NorskGPT-Llama3-8b</td>\n",
       "      <td>16.87 ± 1.51</td>\n",
       "      <td>15.14 ± 1.50</td>\n",
       "      <td>6.14 ± 1.90</td>\n",
       "      <td>60.25 ± 3.14</td>\n",
       "      <td>61.42 ± 3.56</td>\n",
       "      <td>74.57 ± 2.20</td>\n",
       "      <td>59.11 ± 2.44</td>\n",
       "      <td>IT + FNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bineric/NorskGPT-Mistral-7b</td>\n",
       "      <td>30.50 ± 0.91</td>\n",
       "      <td>26.89 ± 1.05</td>\n",
       "      <td>22.54 ± 1.47</td>\n",
       "      <td>47.72 ± 3.74</td>\n",
       "      <td>70.81 ± 1.30</td>\n",
       "      <td>74.38 ± 3.92</td>\n",
       "      <td>60.59 ± 1.18</td>\n",
       "      <td>IT + FNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>google/gemma-2-27b</td>\n",
       "      <td>15.07 ± 0.85</td>\n",
       "      <td>13.97 ± 0.96</td>\n",
       "      <td>6.08 ± 1.06</td>\n",
       "      <td>43.06 ± 1.89</td>\n",
       "      <td>76.14 ± 1.68</td>\n",
       "      <td>80.21 ± 4.49</td>\n",
       "      <td>63.55 ± 4.76</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>google/gemma-2-2b</td>\n",
       "      <td>16.43 ± 1.00</td>\n",
       "      <td>13.08 ± 1.02</td>\n",
       "      <td>4.98 ± 1.34</td>\n",
       "      <td>21.28 ± 2.58</td>\n",
       "      <td>47.91 ± 2.11</td>\n",
       "      <td>63.31 ± 3.73</td>\n",
       "      <td>28.89 ± 1.54</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>google/gemma-2-9b</td>\n",
       "      <td>20.80 ± 1.31</td>\n",
       "      <td>17.02 ± 1.20</td>\n",
       "      <td>7.51 ± 1.41</td>\n",
       "      <td>34.62 ± 1.80</td>\n",
       "      <td>75.53 ± 0.73</td>\n",
       "      <td>72.99 ± 3.16</td>\n",
       "      <td>63.52 ± 3.49</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>meta-llama/Meta-Llama-3-8B</td>\n",
       "      <td>16.23 ± 1.35</td>\n",
       "      <td>14.16 ± 1.18</td>\n",
       "      <td>3.38 ± 1.57</td>\n",
       "      <td>47.65 ± 2.94</td>\n",
       "      <td>66.15 ± 1.44</td>\n",
       "      <td>74.98 ± 3.70</td>\n",
       "      <td>42.47 ± 2.74</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>meta-llama/Meta-Llama-3.1-8B</td>\n",
       "      <td>17.07 ± 1.43</td>\n",
       "      <td>14.48 ± 1.49</td>\n",
       "      <td>4.36 ± 1.70</td>\n",
       "      <td>53.50 ± 3.27</td>\n",
       "      <td>68.71 ± 1.01</td>\n",
       "      <td>75.98 ± 2.62</td>\n",
       "      <td>46.84 ± 1.59</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mistralai/Mistral-7B-v0.1</td>\n",
       "      <td>12.87 ± 0.74</td>\n",
       "      <td>10.31 ± 0.73</td>\n",
       "      <td>-0.20 ± 0.62</td>\n",
       "      <td>43.55 ± 2.21</td>\n",
       "      <td>64.53 ± 3.71</td>\n",
       "      <td>70.86 ± 2.79</td>\n",
       "      <td>32.43 ± 2.67</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>norallm/normistral-7b-scratch</td>\n",
       "      <td>16.47 ± 1.09</td>\n",
       "      <td>13.89 ± 1.41</td>\n",
       "      <td>1.99 ± 1.51</td>\n",
       "      <td>15.44 ± 5.52</td>\n",
       "      <td>36.85 ± 2.01</td>\n",
       "      <td>38.93 ± 2.59</td>\n",
       "      <td>24.84 ± 0.71</td>\n",
       "      <td>PNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>norallm/normistral-7b-warm</td>\n",
       "      <td>17.83 ± 1.29</td>\n",
       "      <td>13.76 ± 1.27</td>\n",
       "      <td>2.31 ± 1.54</td>\n",
       "      <td>31.45 ± 1.88</td>\n",
       "      <td>45.30 ± 3.46</td>\n",
       "      <td>61.85 ± 3.07</td>\n",
       "      <td>25.00 ± 0.83</td>\n",
       "      <td>PNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NorwAI/NorwAI-Mistral-7B</td>\n",
       "      <td>16.83 ± 1.19</td>\n",
       "      <td>12.55 ± 1.24</td>\n",
       "      <td>1.22 ± 1.46</td>\n",
       "      <td>20.45 ± 2.65</td>\n",
       "      <td>65.98 ± 2.95</td>\n",
       "      <td>68.04 ± 5.37</td>\n",
       "      <td>27.82 ± 1.56</td>\n",
       "      <td>PNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>norallm/normistral-7b-warm-instruct</td>\n",
       "      <td>18.30 ± 1.34</td>\n",
       "      <td>9.72 ± 0.83</td>\n",
       "      <td>1.31 ± 1.25</td>\n",
       "      <td>31.87 ± 1.92</td>\n",
       "      <td>43.91 ± 2.51</td>\n",
       "      <td>59.27 ± 1.53</td>\n",
       "      <td>29.64 ± 1.49</td>\n",
       "      <td>PNB + FNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NorwAI/NorwAI-Mistral-7B-instruct</td>\n",
       "      <td>17.17 ± 1.69</td>\n",
       "      <td>13.55 ± 1.49</td>\n",
       "      <td>2.58 ± 1.67</td>\n",
       "      <td>24.26 ± 1.41</td>\n",
       "      <td>64.33 ± 2.80</td>\n",
       "      <td>29.01 ± 1.18</td>\n",
       "      <td>25.82 ± 0.79</td>\n",
       "      <td>PNB + FNB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     model           Acc      Macro F1  \\\n",
       "14                   google/gemma-2-27b-it  60.53 ± 2.31  50.56 ± 1.54   \n",
       "12                    google/gemma-2-2b-it  43.53 ± 2.15  32.62 ± 1.50   \n",
       "13                    google/gemma-2-9b-it  62.10 ± 1.80  53.50 ± 1.50   \n",
       "22          meta-llama/Llama-2-13b-chat-hf   8.93 ± 0.77   6.12 ± 0.85   \n",
       "21           meta-llama/Llama-2-7b-chat-hf   6.40 ± 0.71   2.69 ± 0.41   \n",
       "19     meta-llama/Meta-Llama-3-8B-Instruct  33.03 ± 1.34  26.44 ± 1.23   \n",
       "11   meta-llama/Meta-Llama-3.1-8B-Instruct  24.87 ± 1.13  21.80 ± 1.36   \n",
       "20      mistralai/Mistral-7B-Instruct-v0.1  23.60 ± 1.74  17.33 ± 1.81   \n",
       "1   RuterNorway/Llama-2-13b-chat-norwegian  23.27 ± 1.98  19.79 ± 1.10   \n",
       "0    RuterNorway/Llama-2-7b-chat-norwegian  10.80 ± 1.14   8.69 ± 1.29   \n",
       "7               bineric/NorskGPT-Llama3-8b  16.87 ± 1.51  15.14 ± 1.50   \n",
       "8              bineric/NorskGPT-Mistral-7b  30.50 ± 0.91  26.89 ± 1.05   \n",
       "17                      google/gemma-2-27b  15.07 ± 0.85  13.97 ± 0.96   \n",
       "15                       google/gemma-2-2b  16.43 ± 1.00  13.08 ± 1.02   \n",
       "16                       google/gemma-2-9b  20.80 ± 1.31  17.02 ± 1.20   \n",
       "18              meta-llama/Meta-Llama-3-8B  16.23 ± 1.35  14.16 ± 1.18   \n",
       "10            meta-llama/Meta-Llama-3.1-8B  17.07 ± 1.43  14.48 ± 1.49   \n",
       "9                mistralai/Mistral-7B-v0.1  12.87 ± 0.74  10.31 ± 0.73   \n",
       "4            norallm/normistral-7b-scratch  16.47 ± 1.09  13.89 ± 1.41   \n",
       "3               norallm/normistral-7b-warm  17.83 ± 1.29  13.76 ± 1.27   \n",
       "6                 NorwAI/NorwAI-Mistral-7B  16.83 ± 1.19  12.55 ± 1.24   \n",
       "2      norallm/normistral-7b-warm-instruct  18.30 ± 1.34   9.72 ± 0.83   \n",
       "5        NorwAI/NorwAI-Mistral-7B-instruct  17.17 ± 1.69  13.55 ± 1.49   \n",
       "\n",
       "             MCC       NorNE-nb          NoReC        NorQuAD      HellaSwag  \\\n",
       "14  54.27 ± 2.13   56.75 ± 3.04   78.63 ± 0.96   73.41 ± 1.61   77.92 ± 1.72   \n",
       "12  33.25 ± 1.87   28.77 ± 2.22   63.18 ± 1.91   63.84 ± 1.50   49.42 ± 0.79   \n",
       "13  55.13 ± 1.91   44.91 ± 3.62   73.45 ± 0.94   70.14 ± 1.53   75.79 ± 1.47   \n",
       "22  -0.69 ± 1.36   40.40 ± 2.79   57.45 ± 3.77   69.24 ± 2.68   41.00 ± 1.40   \n",
       "21   0.08 ± 1.32   38.59 ± 2.84   57.09 ± 3.80   61.99 ± 2.34   31.84 ± 1.05   \n",
       "19  25.38 ± 1.67   65.57 ± 2.39   65.69 ± 3.50   69.90 ± 3.17   45.85 ± 1.93   \n",
       "11  16.38 ± 1.93   71.87 ± 0.97   71.58 ± 0.90   70.96 ± 3.00   54.03 ± 0.82   \n",
       "20   8.86 ± 2.33   34.52 ± 1.17   60.88 ± 1.36   63.67 ± 2.98   35.89 ± 1.06   \n",
       "1   14.59 ± 2.05   47.74 ± 2.83   58.47 ± 3.79   65.76 ± 3.07   41.29 ± 1.19   \n",
       "0    2.80 ± 1.51   20.44 ± 2.47   23.50 ± 3.03   50.11 ± 1.80   24.48 ± 0.70   \n",
       "7    6.14 ± 1.90   60.25 ± 3.14   61.42 ± 3.56   74.57 ± 2.20   59.11 ± 2.44   \n",
       "8   22.54 ± 1.47   47.72 ± 3.74   70.81 ± 1.30   74.38 ± 3.92   60.59 ± 1.18   \n",
       "17   6.08 ± 1.06   43.06 ± 1.89   76.14 ± 1.68   80.21 ± 4.49   63.55 ± 4.76   \n",
       "15   4.98 ± 1.34   21.28 ± 2.58   47.91 ± 2.11   63.31 ± 3.73   28.89 ± 1.54   \n",
       "16   7.51 ± 1.41   34.62 ± 1.80   75.53 ± 0.73   72.99 ± 3.16   63.52 ± 3.49   \n",
       "18   3.38 ± 1.57   47.65 ± 2.94   66.15 ± 1.44   74.98 ± 3.70   42.47 ± 2.74   \n",
       "10   4.36 ± 1.70   53.50 ± 3.27   68.71 ± 1.01   75.98 ± 2.62   46.84 ± 1.59   \n",
       "9   -0.20 ± 0.62   43.55 ± 2.21   64.53 ± 3.71   70.86 ± 2.79   32.43 ± 2.67   \n",
       "4    1.99 ± 1.51   15.44 ± 5.52   36.85 ± 2.01   38.93 ± 2.59   24.84 ± 0.71   \n",
       "3    2.31 ± 1.54   31.45 ± 1.88   45.30 ± 3.46   61.85 ± 3.07   25.00 ± 0.83   \n",
       "6    1.22 ± 1.46   20.45 ± 2.65   65.98 ± 2.95   68.04 ± 5.37   27.82 ± 1.56   \n",
       "2    1.31 ± 1.25   31.87 ± 1.92   43.91 ± 2.51   59.27 ± 1.53   29.64 ± 1.49   \n",
       "5    2.58 ± 1.67   24.26 ± 1.41   64.33 ± 2.80   29.01 ± 1.18   25.82 ± 0.79   \n",
       "\n",
       "     category  \n",
       "14         IT  \n",
       "12         IT  \n",
       "13         IT  \n",
       "22         IT  \n",
       "21         IT  \n",
       "19         IT  \n",
       "11         IT  \n",
       "20         IT  \n",
       "1    IT + FNB  \n",
       "0    IT + FNB  \n",
       "7    IT + FNB  \n",
       "8    IT + FNB  \n",
       "17          P  \n",
       "15          P  \n",
       "16          P  \n",
       "18          P  \n",
       "10          P  \n",
       "9           P  \n",
       "4         PNB  \n",
       "3         PNB  \n",
       "6         PNB  \n",
       "2   PNB + FNB  \n",
       "5   PNB + FNB  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from consts import model_tune_map\n",
    "df = df.copy()\n",
    "df[\"category\"] = df[\"model\"].map(model_tune_map)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Acc', 'Macro F1', 'MCC', 'NorNE-nb', 'NoReC', 'NorQuAD', 'HellaSwag']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric = [col for col in df.columns if col not in [\"model\", \"category\"]]\n",
    "numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_44109/646758080.py:6: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  cat_winners = df.groupby(\"category\").apply(\n",
      "/tmp/ipykernel_44109/646758080.py:6: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  cat_winners = df.groupby(\"category\").apply(\n",
      "/tmp/ipykernel_44109/646758080.py:6: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  cat_winners = df.groupby(\"category\").apply(\n",
      "/tmp/ipykernel_44109/646758080.py:6: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  cat_winners = df.groupby(\"category\").apply(\n",
      "/tmp/ipykernel_44109/646758080.py:6: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  cat_winners = df.groupby(\"category\").apply(\n",
      "/tmp/ipykernel_44109/646758080.py:6: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  cat_winners = df.groupby(\"category\").apply(\n",
      "/tmp/ipykernel_44109/646758080.py:6: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  cat_winners = df.groupby(\"category\").apply(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>MCC</th>\n",
       "      <th>NorNE-nb</th>\n",
       "      <th>NoReC</th>\n",
       "      <th>NorQuAD</th>\n",
       "      <th>HellaSwag</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Gemma2 27B IT</td>\n",
       "      <td>60.53 ± 2.31</td>\n",
       "      <td>50.56 ± 1.54</td>\n",
       "      <td>54.27 ± 2.13</td>\n",
       "      <td>56.75 ± 3.04</td>\n",
       "      <td>\\textbf{ 78.63 ± 0.96}</td>\n",
       "      <td>\\textbf{ 73.41 ± 1.61}</td>\n",
       "      <td>\\textbf{ 77.92 ± 1.72}</td>\n",
       "      <td>IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Gemma2 2B IT</td>\n",
       "      <td>43.53 ± 2.15</td>\n",
       "      <td>32.62 ± 1.50</td>\n",
       "      <td>33.25 ± 1.87</td>\n",
       "      <td>28.77 ± 2.22</td>\n",
       "      <td>63.18 ± 1.91</td>\n",
       "      <td>63.84 ± 1.50</td>\n",
       "      <td>49.42 ± 0.79</td>\n",
       "      <td>IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Gemma2 9B IT</td>\n",
       "      <td>\\textbf{62.10 ± 1.80}</td>\n",
       "      <td>\\textbf{53.50 ± 1.50}</td>\n",
       "      <td>\\textbf{55.13 ± 1.91}</td>\n",
       "      <td>44.91 ± 3.62</td>\n",
       "      <td>73.45 ± 0.94</td>\n",
       "      <td>70.14 ± 1.53</td>\n",
       "      <td>75.79 ± 1.47</td>\n",
       "      <td>IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Llama2 13B Chat</td>\n",
       "      <td>8.93 ± 0.77</td>\n",
       "      <td>6.12 ± 0.85</td>\n",
       "      <td>-0.69 ± 1.36</td>\n",
       "      <td>40.40 ± 2.79</td>\n",
       "      <td>57.45 ± 3.77</td>\n",
       "      <td>69.24 ± 2.68</td>\n",
       "      <td>41.00 ± 1.40</td>\n",
       "      <td>IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Llama2 7B Chat</td>\n",
       "      <td>6.40 ± 0.71</td>\n",
       "      <td>2.69 ± 0.41</td>\n",
       "      <td>0.08 ± 1.32</td>\n",
       "      <td>38.59 ± 2.84</td>\n",
       "      <td>57.09 ± 3.80</td>\n",
       "      <td>61.99 ± 2.34</td>\n",
       "      <td>31.84 ± 1.05</td>\n",
       "      <td>IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Llama3 8B IT</td>\n",
       "      <td>33.03 ± 1.34</td>\n",
       "      <td>26.44 ± 1.23</td>\n",
       "      <td>25.38 ± 1.67</td>\n",
       "      <td>65.57 ± 2.39</td>\n",
       "      <td>65.69 ± 3.50</td>\n",
       "      <td>69.90 ± 3.17</td>\n",
       "      <td>45.85 ± 1.93</td>\n",
       "      <td>IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Llama3.1 8B IT</td>\n",
       "      <td>24.87 ± 1.13</td>\n",
       "      <td>21.80 ± 1.36</td>\n",
       "      <td>16.38 ± 1.93</td>\n",
       "      <td>\\textbf{ 71.87 ± 0.97}</td>\n",
       "      <td>71.58 ± 0.90</td>\n",
       "      <td>70.96 ± 3.00</td>\n",
       "      <td>54.03 ± 0.82</td>\n",
       "      <td>IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Mistral 7B v0.1 IT</td>\n",
       "      <td>23.60 ± 1.74</td>\n",
       "      <td>17.33 ± 1.81</td>\n",
       "      <td>8.86 ± 2.33</td>\n",
       "      <td>34.52 ± 1.17</td>\n",
       "      <td>60.88 ± 1.36</td>\n",
       "      <td>63.67 ± 2.98</td>\n",
       "      <td>35.89 ± 1.06</td>\n",
       "      <td>IT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Llama2 13B Chat-Nor</td>\n",
       "      <td>23.27 ± 1.98</td>\n",
       "      <td>19.79 ± 1.10</td>\n",
       "      <td>14.59 ± 2.05</td>\n",
       "      <td>47.74 ± 2.83</td>\n",
       "      <td>58.47 ± 3.79</td>\n",
       "      <td>65.76 ± 3.07</td>\n",
       "      <td>41.29 ± 1.19</td>\n",
       "      <td>IT + FNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Llama2 7B Chat-Nor</td>\n",
       "      <td>10.80 ± 1.14</td>\n",
       "      <td>8.69 ± 1.29</td>\n",
       "      <td>2.80 ± 1.51</td>\n",
       "      <td>20.44 ± 2.47</td>\n",
       "      <td>23.50 ± 3.03</td>\n",
       "      <td>50.11 ± 1.80</td>\n",
       "      <td>24.48 ± 0.70</td>\n",
       "      <td>IT + FNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NorskGPT Llama 3 8B</td>\n",
       "      <td>16.87 ± 1.51</td>\n",
       "      <td>15.14 ± 1.50</td>\n",
       "      <td>6.14 ± 1.90</td>\n",
       "      <td>\\textbf{ 60.25 ± 3.14}</td>\n",
       "      <td>61.42 ± 3.56</td>\n",
       "      <td>\\textbf{ 74.57 ± 2.20}</td>\n",
       "      <td>59.11 ± 2.44</td>\n",
       "      <td>IT + FNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NorskGPT Mistral 7B</td>\n",
       "      <td>\\textbf{30.50 ± 0.91}</td>\n",
       "      <td>\\textbf{26.89 ± 1.05}</td>\n",
       "      <td>\\textbf{22.54 ± 1.47}</td>\n",
       "      <td>47.72 ± 3.74</td>\n",
       "      <td>\\textbf{ 70.81 ± 1.30}</td>\n",
       "      <td>74.38 ± 3.92</td>\n",
       "      <td>\\textbf{ 60.59 ± 1.18}</td>\n",
       "      <td>IT + FNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Gemma2 27B</td>\n",
       "      <td>15.07 ± 0.85</td>\n",
       "      <td>13.97 ± 0.96</td>\n",
       "      <td>6.08 ± 1.06</td>\n",
       "      <td>43.06 ± 1.89</td>\n",
       "      <td>\\textbf{ 76.14 ± 1.68}</td>\n",
       "      <td>\\textbf{ 80.21 ± 4.49}</td>\n",
       "      <td>\\textbf{ 63.55 ± 4.76}</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Gemma2 2B</td>\n",
       "      <td>16.43 ± 1.00</td>\n",
       "      <td>13.08 ± 1.02</td>\n",
       "      <td>4.98 ± 1.34</td>\n",
       "      <td>21.28 ± 2.58</td>\n",
       "      <td>47.91 ± 2.11</td>\n",
       "      <td>63.31 ± 3.73</td>\n",
       "      <td>28.89 ± 1.54</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Gemma2 9B</td>\n",
       "      <td>\\textbf{20.80 ± 1.31}</td>\n",
       "      <td>\\textbf{17.02 ± 1.20}</td>\n",
       "      <td>\\textbf{7.51 ± 1.41}</td>\n",
       "      <td>34.62 ± 1.80</td>\n",
       "      <td>75.53 ± 0.73</td>\n",
       "      <td>72.99 ± 3.16</td>\n",
       "      <td>63.52 ± 3.49</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Llama3 8B</td>\n",
       "      <td>16.23 ± 1.35</td>\n",
       "      <td>14.16 ± 1.18</td>\n",
       "      <td>3.38 ± 1.57</td>\n",
       "      <td>47.65 ± 2.94</td>\n",
       "      <td>66.15 ± 1.44</td>\n",
       "      <td>74.98 ± 3.70</td>\n",
       "      <td>42.47 ± 2.74</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Llama3.1 8B</td>\n",
       "      <td>17.07 ± 1.43</td>\n",
       "      <td>14.48 ± 1.49</td>\n",
       "      <td>4.36 ± 1.70</td>\n",
       "      <td>\\textbf{ 53.50 ± 3.27}</td>\n",
       "      <td>68.71 ± 1.01</td>\n",
       "      <td>75.98 ± 2.62</td>\n",
       "      <td>46.84 ± 1.59</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mistral 7B v0.1</td>\n",
       "      <td>12.87 ± 0.74</td>\n",
       "      <td>10.31 ± 0.73</td>\n",
       "      <td>-0.20 ± 0.62</td>\n",
       "      <td>43.55 ± 2.21</td>\n",
       "      <td>64.53 ± 3.71</td>\n",
       "      <td>70.86 ± 2.79</td>\n",
       "      <td>32.43 ± 2.67</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Normistral 7B Scratch</td>\n",
       "      <td>16.47 ± 1.09</td>\n",
       "      <td>\\textbf{13.89 ± 1.41}</td>\n",
       "      <td>1.99 ± 1.51</td>\n",
       "      <td>15.44 ± 5.52</td>\n",
       "      <td>36.85 ± 2.01</td>\n",
       "      <td>38.93 ± 2.59</td>\n",
       "      <td>24.84 ± 0.71</td>\n",
       "      <td>PNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Normistral 7B Warm</td>\n",
       "      <td>\\textbf{17.83 ± 1.29}</td>\n",
       "      <td>13.76 ± 1.27</td>\n",
       "      <td>\\textbf{2.31 ± 1.54}</td>\n",
       "      <td>\\textbf{ 31.45 ± 1.88}</td>\n",
       "      <td>45.30 ± 3.46</td>\n",
       "      <td>61.85 ± 3.07</td>\n",
       "      <td>25.00 ± 0.83</td>\n",
       "      <td>PNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NorwAI Mistral 7B</td>\n",
       "      <td>16.83 ± 1.19</td>\n",
       "      <td>12.55 ± 1.24</td>\n",
       "      <td>1.22 ± 1.46</td>\n",
       "      <td>20.45 ± 2.65</td>\n",
       "      <td>\\textbf{ 65.98 ± 2.95}</td>\n",
       "      <td>\\textbf{ 68.04 ± 5.37}</td>\n",
       "      <td>\\textbf{ 27.82 ± 1.56}</td>\n",
       "      <td>PNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Normistral 7B Warm IT</td>\n",
       "      <td>\\textbf{18.30 ± 1.34}</td>\n",
       "      <td>9.72 ± 0.83</td>\n",
       "      <td>1.31 ± 1.25</td>\n",
       "      <td>\\textbf{ 31.87 ± 1.92}</td>\n",
       "      <td>43.91 ± 2.51</td>\n",
       "      <td>\\textbf{ 59.27 ± 1.53}</td>\n",
       "      <td>\\textbf{ 29.64 ± 1.49}</td>\n",
       "      <td>PNB + FNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NorwAI Mistral 7B IT</td>\n",
       "      <td>17.17 ± 1.69</td>\n",
       "      <td>\\textbf{13.55 ± 1.49}</td>\n",
       "      <td>\\textbf{2.58 ± 1.67}</td>\n",
       "      <td>24.26 ± 1.41</td>\n",
       "      <td>\\textbf{ 64.33 ± 2.80}</td>\n",
       "      <td>29.01 ± 1.18</td>\n",
       "      <td>25.82 ± 0.79</td>\n",
       "      <td>PNB + FNB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model                    Acc               Macro F1  \\\n",
       "14          Gemma2 27B IT           60.53 ± 2.31           50.56 ± 1.54   \n",
       "12           Gemma2 2B IT           43.53 ± 2.15           32.62 ± 1.50   \n",
       "13           Gemma2 9B IT  \\textbf{62.10 ± 1.80}  \\textbf{53.50 ± 1.50}   \n",
       "22        Llama2 13B Chat            8.93 ± 0.77            6.12 ± 0.85   \n",
       "21         Llama2 7B Chat            6.40 ± 0.71            2.69 ± 0.41   \n",
       "19           Llama3 8B IT           33.03 ± 1.34           26.44 ± 1.23   \n",
       "11         Llama3.1 8B IT           24.87 ± 1.13           21.80 ± 1.36   \n",
       "20     Mistral 7B v0.1 IT           23.60 ± 1.74           17.33 ± 1.81   \n",
       "1     Llama2 13B Chat-Nor           23.27 ± 1.98           19.79 ± 1.10   \n",
       "0      Llama2 7B Chat-Nor           10.80 ± 1.14            8.69 ± 1.29   \n",
       "7     NorskGPT Llama 3 8B           16.87 ± 1.51           15.14 ± 1.50   \n",
       "8     NorskGPT Mistral 7B  \\textbf{30.50 ± 0.91}  \\textbf{26.89 ± 1.05}   \n",
       "17             Gemma2 27B           15.07 ± 0.85           13.97 ± 0.96   \n",
       "15              Gemma2 2B           16.43 ± 1.00           13.08 ± 1.02   \n",
       "16              Gemma2 9B  \\textbf{20.80 ± 1.31}  \\textbf{17.02 ± 1.20}   \n",
       "18              Llama3 8B           16.23 ± 1.35           14.16 ± 1.18   \n",
       "10            Llama3.1 8B           17.07 ± 1.43           14.48 ± 1.49   \n",
       "9         Mistral 7B v0.1           12.87 ± 0.74           10.31 ± 0.73   \n",
       "4   Normistral 7B Scratch           16.47 ± 1.09  \\textbf{13.89 ± 1.41}   \n",
       "3      Normistral 7B Warm  \\textbf{17.83 ± 1.29}           13.76 ± 1.27   \n",
       "6       NorwAI Mistral 7B           16.83 ± 1.19           12.55 ± 1.24   \n",
       "2   Normistral 7B Warm IT  \\textbf{18.30 ± 1.34}            9.72 ± 0.83   \n",
       "5    NorwAI Mistral 7B IT           17.17 ± 1.69  \\textbf{13.55 ± 1.49}   \n",
       "\n",
       "                      MCC                NorNE-nb                   NoReC  \\\n",
       "14           54.27 ± 2.13            56.75 ± 3.04  \\textbf{ 78.63 ± 0.96}   \n",
       "12           33.25 ± 1.87            28.77 ± 2.22            63.18 ± 1.91   \n",
       "13  \\textbf{55.13 ± 1.91}            44.91 ± 3.62            73.45 ± 0.94   \n",
       "22           -0.69 ± 1.36            40.40 ± 2.79            57.45 ± 3.77   \n",
       "21            0.08 ± 1.32            38.59 ± 2.84            57.09 ± 3.80   \n",
       "19           25.38 ± 1.67            65.57 ± 2.39            65.69 ± 3.50   \n",
       "11           16.38 ± 1.93  \\textbf{ 71.87 ± 0.97}            71.58 ± 0.90   \n",
       "20            8.86 ± 2.33            34.52 ± 1.17            60.88 ± 1.36   \n",
       "1            14.59 ± 2.05            47.74 ± 2.83            58.47 ± 3.79   \n",
       "0             2.80 ± 1.51            20.44 ± 2.47            23.50 ± 3.03   \n",
       "7             6.14 ± 1.90  \\textbf{ 60.25 ± 3.14}            61.42 ± 3.56   \n",
       "8   \\textbf{22.54 ± 1.47}            47.72 ± 3.74  \\textbf{ 70.81 ± 1.30}   \n",
       "17            6.08 ± 1.06            43.06 ± 1.89  \\textbf{ 76.14 ± 1.68}   \n",
       "15            4.98 ± 1.34            21.28 ± 2.58            47.91 ± 2.11   \n",
       "16   \\textbf{7.51 ± 1.41}            34.62 ± 1.80            75.53 ± 0.73   \n",
       "18            3.38 ± 1.57            47.65 ± 2.94            66.15 ± 1.44   \n",
       "10            4.36 ± 1.70  \\textbf{ 53.50 ± 3.27}            68.71 ± 1.01   \n",
       "9            -0.20 ± 0.62            43.55 ± 2.21            64.53 ± 3.71   \n",
       "4             1.99 ± 1.51            15.44 ± 5.52            36.85 ± 2.01   \n",
       "3    \\textbf{2.31 ± 1.54}  \\textbf{ 31.45 ± 1.88}            45.30 ± 3.46   \n",
       "6             1.22 ± 1.46            20.45 ± 2.65  \\textbf{ 65.98 ± 2.95}   \n",
       "2             1.31 ± 1.25  \\textbf{ 31.87 ± 1.92}            43.91 ± 2.51   \n",
       "5    \\textbf{2.58 ± 1.67}            24.26 ± 1.41  \\textbf{ 64.33 ± 2.80}   \n",
       "\n",
       "                   NorQuAD               HellaSwag   category  \n",
       "14  \\textbf{ 73.41 ± 1.61}  \\textbf{ 77.92 ± 1.72}         IT  \n",
       "12            63.84 ± 1.50            49.42 ± 0.79         IT  \n",
       "13            70.14 ± 1.53            75.79 ± 1.47         IT  \n",
       "22            69.24 ± 2.68            41.00 ± 1.40         IT  \n",
       "21            61.99 ± 2.34            31.84 ± 1.05         IT  \n",
       "19            69.90 ± 3.17            45.85 ± 1.93         IT  \n",
       "11            70.96 ± 3.00            54.03 ± 0.82         IT  \n",
       "20            63.67 ± 2.98            35.89 ± 1.06         IT  \n",
       "1             65.76 ± 3.07            41.29 ± 1.19   IT + FNB  \n",
       "0             50.11 ± 1.80            24.48 ± 0.70   IT + FNB  \n",
       "7   \\textbf{ 74.57 ± 2.20}            59.11 ± 2.44   IT + FNB  \n",
       "8             74.38 ± 3.92  \\textbf{ 60.59 ± 1.18}   IT + FNB  \n",
       "17  \\textbf{ 80.21 ± 4.49}  \\textbf{ 63.55 ± 4.76}          P  \n",
       "15            63.31 ± 3.73            28.89 ± 1.54          P  \n",
       "16            72.99 ± 3.16            63.52 ± 3.49          P  \n",
       "18            74.98 ± 3.70            42.47 ± 2.74          P  \n",
       "10            75.98 ± 2.62            46.84 ± 1.59          P  \n",
       "9             70.86 ± 2.79            32.43 ± 2.67          P  \n",
       "4             38.93 ± 2.59            24.84 ± 0.71        PNB  \n",
       "3             61.85 ± 3.07            25.00 ± 0.83        PNB  \n",
       "6   \\textbf{ 68.04 ± 5.37}  \\textbf{ 27.82 ± 1.56}        PNB  \n",
       "2   \\textbf{ 59.27 ± 1.53}  \\textbf{ 29.64 ± 1.49}  PNB + FNB  \n",
       "5             29.01 ± 1.18            25.82 ± 0.79  PNB + FNB  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from consts import model_map\n",
    "sort_fn = lambda x: x.astype(float)\n",
    "sort_fn_std = lambda x: x.str.split(\" ± \").str[0].astype(float)\n",
    "\n",
    "def boldface_by_column_value(df, column: str, ascending=False, sort_fn=sort_fn, kind=\"textbf\"):\n",
    "    cat_winners = df.groupby(\"category\").apply(\n",
    "        lambda x: x.sort_values(\n",
    "            column, ascending=ascending, key=sort_fn\n",
    "        ).head(1)\n",
    "    )\n",
    "    for idx, row in cat_winners.iterrows():\n",
    "        model = row[\"model\"]\n",
    "        df.loc[df[\"model\"] == model, column] =  f\"\\\\{kind}{{{df.loc[df['model'] == model, column].values[0]}}}\"\n",
    "\n",
    "    return df\n",
    "\n",
    "boldface = df.copy()\n",
    "for col in numeric:\n",
    "    boldface = boldface_by_column_value(boldface, col, ascending=False, sort_fn=sort_fn_std)\n",
    "# drop full-desc and keyword:\n",
    "# boldface = boldface_by_column_value(boldface, \"mean ± std\", ascending=False, sort_fn=sort_fn_std)\n",
    "# boldface = boldface_by_column_value(boldface, \"NorNE-nb\", sort_fn=sort_fn_std)\n",
    "# boldface = boldface_by_column_value(boldface, \"NoReC\", sort_fn=sort_fn_std)\n",
    "# boldface = boldface_by_column_value(boldface, \"NorQuAD\", sort_fn=sort_fn_std)\n",
    "# boldface = boldface_by_column_value(boldface, \"HellaSwag\", sort_fn=sort_fn_std)\n",
    "# # convert all values to strings with 2 decimal points\n",
    "# # map all model names to model_map equi\n",
    "boldface[\"model\"] = boldface[\"model\"].map(model_map)\n",
    "boldface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IT\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>MCC</th>\n",
       "      <th>NorNE-nb</th>\n",
       "      <th>NoReC</th>\n",
       "      <th>NorQuAD</th>\n",
       "      <th>HellaSwag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Gemma2 27B IT</td>\n",
       "      <td>60.53 ± 2.31</td>\n",
       "      <td>50.56 ± 1.54</td>\n",
       "      <td>54.27 ± 2.13</td>\n",
       "      <td>56.75 ± 3.04</td>\n",
       "      <td>\\textbf{ 78.63 ± 0.96}</td>\n",
       "      <td>\\textbf{ 73.41 ± 1.61}</td>\n",
       "      <td>\\textbf{ 77.92 ± 1.72}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Gemma2 2B IT</td>\n",
       "      <td>43.53 ± 2.15</td>\n",
       "      <td>32.62 ± 1.50</td>\n",
       "      <td>33.25 ± 1.87</td>\n",
       "      <td>28.77 ± 2.22</td>\n",
       "      <td>63.18 ± 1.91</td>\n",
       "      <td>63.84 ± 1.50</td>\n",
       "      <td>49.42 ± 0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Gemma2 9B IT</td>\n",
       "      <td>\\textbf{62.10 ± 1.80}</td>\n",
       "      <td>\\textbf{53.50 ± 1.50}</td>\n",
       "      <td>\\textbf{55.13 ± 1.91}</td>\n",
       "      <td>44.91 ± 3.62</td>\n",
       "      <td>73.45 ± 0.94</td>\n",
       "      <td>70.14 ± 1.53</td>\n",
       "      <td>75.79 ± 1.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Llama2 13B Chat</td>\n",
       "      <td>8.93 ± 0.77</td>\n",
       "      <td>6.12 ± 0.85</td>\n",
       "      <td>-0.69 ± 1.36</td>\n",
       "      <td>40.40 ± 2.79</td>\n",
       "      <td>57.45 ± 3.77</td>\n",
       "      <td>69.24 ± 2.68</td>\n",
       "      <td>41.00 ± 1.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Llama2 7B Chat</td>\n",
       "      <td>6.40 ± 0.71</td>\n",
       "      <td>2.69 ± 0.41</td>\n",
       "      <td>0.08 ± 1.32</td>\n",
       "      <td>38.59 ± 2.84</td>\n",
       "      <td>57.09 ± 3.80</td>\n",
       "      <td>61.99 ± 2.34</td>\n",
       "      <td>31.84 ± 1.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Llama3 8B IT</td>\n",
       "      <td>33.03 ± 1.34</td>\n",
       "      <td>26.44 ± 1.23</td>\n",
       "      <td>25.38 ± 1.67</td>\n",
       "      <td>65.57 ± 2.39</td>\n",
       "      <td>65.69 ± 3.50</td>\n",
       "      <td>69.90 ± 3.17</td>\n",
       "      <td>45.85 ± 1.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Llama3.1 8B IT</td>\n",
       "      <td>24.87 ± 1.13</td>\n",
       "      <td>21.80 ± 1.36</td>\n",
       "      <td>16.38 ± 1.93</td>\n",
       "      <td>\\textbf{ 71.87 ± 0.97}</td>\n",
       "      <td>71.58 ± 0.90</td>\n",
       "      <td>70.96 ± 3.00</td>\n",
       "      <td>54.03 ± 0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Mistral 7B v0.1 IT</td>\n",
       "      <td>23.60 ± 1.74</td>\n",
       "      <td>17.33 ± 1.81</td>\n",
       "      <td>8.86 ± 2.33</td>\n",
       "      <td>34.52 ± 1.17</td>\n",
       "      <td>60.88 ± 1.36</td>\n",
       "      <td>63.67 ± 2.98</td>\n",
       "      <td>35.89 ± 1.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model                    Acc               Macro F1  \\\n",
       "14       Gemma2 27B IT           60.53 ± 2.31           50.56 ± 1.54   \n",
       "12        Gemma2 2B IT           43.53 ± 2.15           32.62 ± 1.50   \n",
       "13        Gemma2 9B IT  \\textbf{62.10 ± 1.80}  \\textbf{53.50 ± 1.50}   \n",
       "22     Llama2 13B Chat            8.93 ± 0.77            6.12 ± 0.85   \n",
       "21      Llama2 7B Chat            6.40 ± 0.71            2.69 ± 0.41   \n",
       "19        Llama3 8B IT           33.03 ± 1.34           26.44 ± 1.23   \n",
       "11      Llama3.1 8B IT           24.87 ± 1.13           21.80 ± 1.36   \n",
       "20  Mistral 7B v0.1 IT           23.60 ± 1.74           17.33 ± 1.81   \n",
       "\n",
       "                      MCC                NorNE-nb                   NoReC  \\\n",
       "14           54.27 ± 2.13            56.75 ± 3.04  \\textbf{ 78.63 ± 0.96}   \n",
       "12           33.25 ± 1.87            28.77 ± 2.22            63.18 ± 1.91   \n",
       "13  \\textbf{55.13 ± 1.91}            44.91 ± 3.62            73.45 ± 0.94   \n",
       "22           -0.69 ± 1.36            40.40 ± 2.79            57.45 ± 3.77   \n",
       "21            0.08 ± 1.32            38.59 ± 2.84            57.09 ± 3.80   \n",
       "19           25.38 ± 1.67            65.57 ± 2.39            65.69 ± 3.50   \n",
       "11           16.38 ± 1.93  \\textbf{ 71.87 ± 0.97}            71.58 ± 0.90   \n",
       "20            8.86 ± 2.33            34.52 ± 1.17            60.88 ± 1.36   \n",
       "\n",
       "                   NorQuAD               HellaSwag  \n",
       "14  \\textbf{ 73.41 ± 1.61}  \\textbf{ 77.92 ± 1.72}  \n",
       "12            63.84 ± 1.50            49.42 ± 0.79  \n",
       "13            70.14 ± 1.53            75.79 ± 1.47  \n",
       "22            69.24 ± 2.68            41.00 ± 1.40  \n",
       "21            61.99 ± 2.34            31.84 ± 1.05  \n",
       "19            69.90 ± 3.17            45.85 ± 1.93  \n",
       "11            70.96 ± 3.00            54.03 ± 0.82  \n",
       "20            63.67 ± 2.98            35.89 ± 1.06  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\multicolumn9{l}{\\textbf{Category: IT}}\\\\\n",
      "\\begin{tabular}{lrrrr|rrrr}\n",
      "\\toprule\n",
      "model & Acc & Macro F1 & MCC & NorNE-nb & NoReC & NorQuAD & HellaSwag \\\\\n",
      "\\midrule\n",
      "Gemma2 27B IT & 60.53 ± 2.31 & 50.56 ± 1.54 & 54.27 ± 2.13 &  56.75 ± 3.04 & \\textbf{ 78.63 ± 0.96} & \\textbf{ 73.41 ± 1.61} & \\textbf{ 77.92 ± 1.72} \\\\\n",
      "Gemma2 2B IT & 43.53 ± 2.15 & 32.62 ± 1.50 & 33.25 ± 1.87 &  28.77 ± 2.22 &  63.18 ± 1.91 &  63.84 ± 1.50 &  49.42 ± 0.79 \\\\\n",
      "Gemma2 9B IT & \\textbf{62.10 ± 1.80} & \\textbf{53.50 ± 1.50} & \\textbf{55.13 ± 1.91} &  44.91 ± 3.62 &  73.45 ± 0.94 &  70.14 ± 1.53 &  75.79 ± 1.47 \\\\\n",
      "Llama2 13B Chat & 8.93 ± 0.77 & 6.12 ± 0.85 & -0.69 ± 1.36 &  40.40 ± 2.79 &  57.45 ± 3.77 &  69.24 ± 2.68 &  41.00 ± 1.40 \\\\\n",
      "Llama2 7B Chat & 6.40 ± 0.71 & 2.69 ± 0.41 & 0.08 ± 1.32 &  38.59 ± 2.84 &  57.09 ± 3.80 &  61.99 ± 2.34 &  31.84 ± 1.05 \\\\\n",
      "Llama3 8B IT & 33.03 ± 1.34 & 26.44 ± 1.23 & 25.38 ± 1.67 &  65.57 ± 2.39 &  65.69 ± 3.50 &  69.90 ± 3.17 &  45.85 ± 1.93 \\\\\n",
      "Llama3.1 8B IT & 24.87 ± 1.13 & 21.80 ± 1.36 & 16.38 ± 1.93 & \\textbf{ 71.87 ± 0.97} &  71.58 ± 0.90 &  70.96 ± 3.00 &  54.03 ± 0.82 \\\\\n",
      "Mistral 7B v0.1 IT & 23.60 ± 1.74 & 17.33 ± 1.81 & 8.86 ± 2.33 &  34.52 ± 1.17 &  60.88 ± 1.36 &  63.67 ± 2.98 &  35.89 ± 1.06 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\n",
      "IT + FNB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>MCC</th>\n",
       "      <th>NorNE-nb</th>\n",
       "      <th>NoReC</th>\n",
       "      <th>NorQuAD</th>\n",
       "      <th>HellaSwag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Llama2 13B Chat-Nor</td>\n",
       "      <td>23.27 ± 1.98</td>\n",
       "      <td>19.79 ± 1.10</td>\n",
       "      <td>14.59 ± 2.05</td>\n",
       "      <td>47.74 ± 2.83</td>\n",
       "      <td>58.47 ± 3.79</td>\n",
       "      <td>65.76 ± 3.07</td>\n",
       "      <td>41.29 ± 1.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Llama2 7B Chat-Nor</td>\n",
       "      <td>10.80 ± 1.14</td>\n",
       "      <td>8.69 ± 1.29</td>\n",
       "      <td>2.80 ± 1.51</td>\n",
       "      <td>20.44 ± 2.47</td>\n",
       "      <td>23.50 ± 3.03</td>\n",
       "      <td>50.11 ± 1.80</td>\n",
       "      <td>24.48 ± 0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NorskGPT Llama 3 8B</td>\n",
       "      <td>16.87 ± 1.51</td>\n",
       "      <td>15.14 ± 1.50</td>\n",
       "      <td>6.14 ± 1.90</td>\n",
       "      <td>\\textbf{ 60.25 ± 3.14}</td>\n",
       "      <td>61.42 ± 3.56</td>\n",
       "      <td>\\textbf{ 74.57 ± 2.20}</td>\n",
       "      <td>59.11 ± 2.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NorskGPT Mistral 7B</td>\n",
       "      <td>\\textbf{30.50 ± 0.91}</td>\n",
       "      <td>\\textbf{26.89 ± 1.05}</td>\n",
       "      <td>\\textbf{22.54 ± 1.47}</td>\n",
       "      <td>47.72 ± 3.74</td>\n",
       "      <td>\\textbf{ 70.81 ± 1.30}</td>\n",
       "      <td>74.38 ± 3.92</td>\n",
       "      <td>\\textbf{ 60.59 ± 1.18}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model                    Acc               Macro F1  \\\n",
       "1  Llama2 13B Chat-Nor           23.27 ± 1.98           19.79 ± 1.10   \n",
       "0   Llama2 7B Chat-Nor           10.80 ± 1.14            8.69 ± 1.29   \n",
       "7  NorskGPT Llama 3 8B           16.87 ± 1.51           15.14 ± 1.50   \n",
       "8  NorskGPT Mistral 7B  \\textbf{30.50 ± 0.91}  \\textbf{26.89 ± 1.05}   \n",
       "\n",
       "                     MCC                NorNE-nb                   NoReC  \\\n",
       "1           14.59 ± 2.05            47.74 ± 2.83            58.47 ± 3.79   \n",
       "0            2.80 ± 1.51            20.44 ± 2.47            23.50 ± 3.03   \n",
       "7            6.14 ± 1.90  \\textbf{ 60.25 ± 3.14}            61.42 ± 3.56   \n",
       "8  \\textbf{22.54 ± 1.47}            47.72 ± 3.74  \\textbf{ 70.81 ± 1.30}   \n",
       "\n",
       "                  NorQuAD               HellaSwag  \n",
       "1            65.76 ± 3.07            41.29 ± 1.19  \n",
       "0            50.11 ± 1.80            24.48 ± 0.70  \n",
       "7  \\textbf{ 74.57 ± 2.20}            59.11 ± 2.44  \n",
       "8            74.38 ± 3.92  \\textbf{ 60.59 ± 1.18}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\multicolumn9{l}{\\textbf{Category: IT + FNB}}\\\\\n",
      "\\begin{tabular}{lrrrr|rrrr}\n",
      "\\toprule\n",
      "model & Acc & Macro F1 & MCC & NorNE-nb & NoReC & NorQuAD & HellaSwag \\\\\n",
      "\\midrule\n",
      "Llama2 13B Chat-Nor & 23.27 ± 1.98 & 19.79 ± 1.10 & 14.59 ± 2.05 &  47.74 ± 2.83 &  58.47 ± 3.79 &  65.76 ± 3.07 &  41.29 ± 1.19 \\\\\n",
      "Llama2 7B Chat-Nor & 10.80 ± 1.14 & 8.69 ± 1.29 & 2.80 ± 1.51 &  20.44 ± 2.47 &  23.50 ± 3.03 &  50.11 ± 1.80 &  24.48 ± 0.70 \\\\\n",
      "NorskGPT Llama 3 8B & 16.87 ± 1.51 & 15.14 ± 1.50 & 6.14 ± 1.90 & \\textbf{ 60.25 ± 3.14} &  61.42 ± 3.56 & \\textbf{ 74.57 ± 2.20} &  59.11 ± 2.44 \\\\\n",
      "NorskGPT Mistral 7B & \\textbf{30.50 ± 0.91} & \\textbf{26.89 ± 1.05} & \\textbf{22.54 ± 1.47} &  47.72 ± 3.74 & \\textbf{ 70.81 ± 1.30} &  74.38 ± 3.92 & \\textbf{ 60.59 ± 1.18} \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\n",
      "P\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>MCC</th>\n",
       "      <th>NorNE-nb</th>\n",
       "      <th>NoReC</th>\n",
       "      <th>NorQuAD</th>\n",
       "      <th>HellaSwag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Gemma2 27B</td>\n",
       "      <td>15.07 ± 0.85</td>\n",
       "      <td>13.97 ± 0.96</td>\n",
       "      <td>6.08 ± 1.06</td>\n",
       "      <td>43.06 ± 1.89</td>\n",
       "      <td>\\textbf{ 76.14 ± 1.68}</td>\n",
       "      <td>\\textbf{ 80.21 ± 4.49}</td>\n",
       "      <td>\\textbf{ 63.55 ± 4.76}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Gemma2 2B</td>\n",
       "      <td>16.43 ± 1.00</td>\n",
       "      <td>13.08 ± 1.02</td>\n",
       "      <td>4.98 ± 1.34</td>\n",
       "      <td>21.28 ± 2.58</td>\n",
       "      <td>47.91 ± 2.11</td>\n",
       "      <td>63.31 ± 3.73</td>\n",
       "      <td>28.89 ± 1.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Gemma2 9B</td>\n",
       "      <td>\\textbf{20.80 ± 1.31}</td>\n",
       "      <td>\\textbf{17.02 ± 1.20}</td>\n",
       "      <td>\\textbf{7.51 ± 1.41}</td>\n",
       "      <td>34.62 ± 1.80</td>\n",
       "      <td>75.53 ± 0.73</td>\n",
       "      <td>72.99 ± 3.16</td>\n",
       "      <td>63.52 ± 3.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Llama3 8B</td>\n",
       "      <td>16.23 ± 1.35</td>\n",
       "      <td>14.16 ± 1.18</td>\n",
       "      <td>3.38 ± 1.57</td>\n",
       "      <td>47.65 ± 2.94</td>\n",
       "      <td>66.15 ± 1.44</td>\n",
       "      <td>74.98 ± 3.70</td>\n",
       "      <td>42.47 ± 2.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Llama3.1 8B</td>\n",
       "      <td>17.07 ± 1.43</td>\n",
       "      <td>14.48 ± 1.49</td>\n",
       "      <td>4.36 ± 1.70</td>\n",
       "      <td>\\textbf{ 53.50 ± 3.27}</td>\n",
       "      <td>68.71 ± 1.01</td>\n",
       "      <td>75.98 ± 2.62</td>\n",
       "      <td>46.84 ± 1.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mistral 7B v0.1</td>\n",
       "      <td>12.87 ± 0.74</td>\n",
       "      <td>10.31 ± 0.73</td>\n",
       "      <td>-0.20 ± 0.62</td>\n",
       "      <td>43.55 ± 2.21</td>\n",
       "      <td>64.53 ± 3.71</td>\n",
       "      <td>70.86 ± 2.79</td>\n",
       "      <td>32.43 ± 2.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model                    Acc               Macro F1  \\\n",
       "17       Gemma2 27B           15.07 ± 0.85           13.97 ± 0.96   \n",
       "15        Gemma2 2B           16.43 ± 1.00           13.08 ± 1.02   \n",
       "16        Gemma2 9B  \\textbf{20.80 ± 1.31}  \\textbf{17.02 ± 1.20}   \n",
       "18        Llama3 8B           16.23 ± 1.35           14.16 ± 1.18   \n",
       "10      Llama3.1 8B           17.07 ± 1.43           14.48 ± 1.49   \n",
       "9   Mistral 7B v0.1           12.87 ± 0.74           10.31 ± 0.73   \n",
       "\n",
       "                     MCC                NorNE-nb                   NoReC  \\\n",
       "17           6.08 ± 1.06            43.06 ± 1.89  \\textbf{ 76.14 ± 1.68}   \n",
       "15           4.98 ± 1.34            21.28 ± 2.58            47.91 ± 2.11   \n",
       "16  \\textbf{7.51 ± 1.41}            34.62 ± 1.80            75.53 ± 0.73   \n",
       "18           3.38 ± 1.57            47.65 ± 2.94            66.15 ± 1.44   \n",
       "10           4.36 ± 1.70  \\textbf{ 53.50 ± 3.27}            68.71 ± 1.01   \n",
       "9           -0.20 ± 0.62            43.55 ± 2.21            64.53 ± 3.71   \n",
       "\n",
       "                   NorQuAD               HellaSwag  \n",
       "17  \\textbf{ 80.21 ± 4.49}  \\textbf{ 63.55 ± 4.76}  \n",
       "15            63.31 ± 3.73            28.89 ± 1.54  \n",
       "16            72.99 ± 3.16            63.52 ± 3.49  \n",
       "18            74.98 ± 3.70            42.47 ± 2.74  \n",
       "10            75.98 ± 2.62            46.84 ± 1.59  \n",
       "9             70.86 ± 2.79            32.43 ± 2.67  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\multicolumn9{l}{\\textbf{Category: P}}\\\\\n",
      "\\begin{tabular}{lrrrr|rrrr}\n",
      "\\toprule\n",
      "model & Acc & Macro F1 & MCC & NorNE-nb & NoReC & NorQuAD & HellaSwag \\\\\n",
      "\\midrule\n",
      "Gemma2 27B & 15.07 ± 0.85 & 13.97 ± 0.96 & 6.08 ± 1.06 &  43.06 ± 1.89 & \\textbf{ 76.14 ± 1.68} & \\textbf{ 80.21 ± 4.49} & \\textbf{ 63.55 ± 4.76} \\\\\n",
      "Gemma2 2B & 16.43 ± 1.00 & 13.08 ± 1.02 & 4.98 ± 1.34 &  21.28 ± 2.58 &  47.91 ± 2.11 &  63.31 ± 3.73 &  28.89 ± 1.54 \\\\\n",
      "Gemma2 9B & \\textbf{20.80 ± 1.31} & \\textbf{17.02 ± 1.20} & \\textbf{7.51 ± 1.41} &  34.62 ± 1.80 &  75.53 ± 0.73 &  72.99 ± 3.16 &  63.52 ± 3.49 \\\\\n",
      "Llama3 8B & 16.23 ± 1.35 & 14.16 ± 1.18 & 3.38 ± 1.57 &  47.65 ± 2.94 &  66.15 ± 1.44 &  74.98 ± 3.70 &  42.47 ± 2.74 \\\\\n",
      "Llama3.1 8B & 17.07 ± 1.43 & 14.48 ± 1.49 & 4.36 ± 1.70 & \\textbf{ 53.50 ± 3.27} &  68.71 ± 1.01 &  75.98 ± 2.62 &  46.84 ± 1.59 \\\\\n",
      "Mistral 7B v0.1 & 12.87 ± 0.74 & 10.31 ± 0.73 & -0.20 ± 0.62 &  43.55 ± 2.21 &  64.53 ± 3.71 &  70.86 ± 2.79 &  32.43 ± 2.67 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\n",
      "PNB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>MCC</th>\n",
       "      <th>NorNE-nb</th>\n",
       "      <th>NoReC</th>\n",
       "      <th>NorQuAD</th>\n",
       "      <th>HellaSwag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Normistral 7B Scratch</td>\n",
       "      <td>16.47 ± 1.09</td>\n",
       "      <td>\\textbf{13.89 ± 1.41}</td>\n",
       "      <td>1.99 ± 1.51</td>\n",
       "      <td>15.44 ± 5.52</td>\n",
       "      <td>36.85 ± 2.01</td>\n",
       "      <td>38.93 ± 2.59</td>\n",
       "      <td>24.84 ± 0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Normistral 7B Warm</td>\n",
       "      <td>\\textbf{17.83 ± 1.29}</td>\n",
       "      <td>13.76 ± 1.27</td>\n",
       "      <td>\\textbf{2.31 ± 1.54}</td>\n",
       "      <td>\\textbf{ 31.45 ± 1.88}</td>\n",
       "      <td>45.30 ± 3.46</td>\n",
       "      <td>61.85 ± 3.07</td>\n",
       "      <td>25.00 ± 0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NorwAI Mistral 7B</td>\n",
       "      <td>16.83 ± 1.19</td>\n",
       "      <td>12.55 ± 1.24</td>\n",
       "      <td>1.22 ± 1.46</td>\n",
       "      <td>20.45 ± 2.65</td>\n",
       "      <td>\\textbf{ 65.98 ± 2.95}</td>\n",
       "      <td>\\textbf{ 68.04 ± 5.37}</td>\n",
       "      <td>\\textbf{ 27.82 ± 1.56}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model                    Acc               Macro F1  \\\n",
       "4  Normistral 7B Scratch           16.47 ± 1.09  \\textbf{13.89 ± 1.41}   \n",
       "3     Normistral 7B Warm  \\textbf{17.83 ± 1.29}           13.76 ± 1.27   \n",
       "6      NorwAI Mistral 7B           16.83 ± 1.19           12.55 ± 1.24   \n",
       "\n",
       "                    MCC                NorNE-nb                   NoReC  \\\n",
       "4           1.99 ± 1.51            15.44 ± 5.52            36.85 ± 2.01   \n",
       "3  \\textbf{2.31 ± 1.54}  \\textbf{ 31.45 ± 1.88}            45.30 ± 3.46   \n",
       "6           1.22 ± 1.46            20.45 ± 2.65  \\textbf{ 65.98 ± 2.95}   \n",
       "\n",
       "                  NorQuAD               HellaSwag  \n",
       "4            38.93 ± 2.59            24.84 ± 0.71  \n",
       "3            61.85 ± 3.07            25.00 ± 0.83  \n",
       "6  \\textbf{ 68.04 ± 5.37}  \\textbf{ 27.82 ± 1.56}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\multicolumn9{l}{\\textbf{Category: PNB}}\\\\\n",
      "\\begin{tabular}{lrrrr|rrrr}\n",
      "\\toprule\n",
      "model & Acc & Macro F1 & MCC & NorNE-nb & NoReC & NorQuAD & HellaSwag \\\\\n",
      "\\midrule\n",
      "Normistral 7B Scratch & 16.47 ± 1.09 & \\textbf{13.89 ± 1.41} & 1.99 ± 1.51 &  15.44 ± 5.52 &  36.85 ± 2.01 &  38.93 ± 2.59 &  24.84 ± 0.71 \\\\\n",
      "Normistral 7B Warm & \\textbf{17.83 ± 1.29} & 13.76 ± 1.27 & \\textbf{2.31 ± 1.54} & \\textbf{ 31.45 ± 1.88} &  45.30 ± 3.46 &  61.85 ± 3.07 &  25.00 ± 0.83 \\\\\n",
      "NorwAI Mistral 7B & 16.83 ± 1.19 & 12.55 ± 1.24 & 1.22 ± 1.46 &  20.45 ± 2.65 & \\textbf{ 65.98 ± 2.95} & \\textbf{ 68.04 ± 5.37} & \\textbf{ 27.82 ± 1.56} \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\n",
      "PNB + FNB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>MCC</th>\n",
       "      <th>NorNE-nb</th>\n",
       "      <th>NoReC</th>\n",
       "      <th>NorQuAD</th>\n",
       "      <th>HellaSwag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Normistral 7B Warm IT</td>\n",
       "      <td>\\textbf{18.30 ± 1.34}</td>\n",
       "      <td>9.72 ± 0.83</td>\n",
       "      <td>1.31 ± 1.25</td>\n",
       "      <td>\\textbf{ 31.87 ± 1.92}</td>\n",
       "      <td>43.91 ± 2.51</td>\n",
       "      <td>\\textbf{ 59.27 ± 1.53}</td>\n",
       "      <td>\\textbf{ 29.64 ± 1.49}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NorwAI Mistral 7B IT</td>\n",
       "      <td>17.17 ± 1.69</td>\n",
       "      <td>\\textbf{13.55 ± 1.49}</td>\n",
       "      <td>\\textbf{2.58 ± 1.67}</td>\n",
       "      <td>24.26 ± 1.41</td>\n",
       "      <td>\\textbf{ 64.33 ± 2.80}</td>\n",
       "      <td>29.01 ± 1.18</td>\n",
       "      <td>25.82 ± 0.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model                    Acc               Macro F1  \\\n",
       "2  Normistral 7B Warm IT  \\textbf{18.30 ± 1.34}            9.72 ± 0.83   \n",
       "5   NorwAI Mistral 7B IT           17.17 ± 1.69  \\textbf{13.55 ± 1.49}   \n",
       "\n",
       "                    MCC                NorNE-nb                   NoReC  \\\n",
       "2           1.31 ± 1.25  \\textbf{ 31.87 ± 1.92}            43.91 ± 2.51   \n",
       "5  \\textbf{2.58 ± 1.67}            24.26 ± 1.41  \\textbf{ 64.33 ± 2.80}   \n",
       "\n",
       "                  NorQuAD               HellaSwag  \n",
       "2  \\textbf{ 59.27 ± 1.53}  \\textbf{ 29.64 ± 1.49}  \n",
       "5            29.01 ± 1.18            25.82 ± 0.79  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\multicolumn9{l}{\\textbf{Category: PNB + FNB}}\\\\\n",
      "\\begin{tabular}{lrrrr|rrrr}\n",
      "\\toprule\n",
      "model & Acc & Macro F1 & MCC & NorNE-nb & NoReC & NorQuAD & HellaSwag \\\\\n",
      "\\midrule\n",
      "Normistral 7B Warm IT & \\textbf{18.30 ± 1.34} & 9.72 ± 0.83 & 1.31 ± 1.25 & \\textbf{ 31.87 ± 1.92} &  43.91 ± 2.51 & \\textbf{ 59.27 ± 1.53} & \\textbf{ 29.64 ± 1.49} \\\\\n",
      "NorwAI Mistral 7B IT & 17.17 ± 1.69 & \\textbf{13.55 ± 1.49} & \\textbf{2.58 ± 1.67} &  24.26 ± 1.41 & \\textbf{ 64.33 ± 2.80} &  29.01 ± 1.18 &  25.82 ± 0.79 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['\\n\\\\begin{table*}[!htbp]\\n    \\\\centering\\n    \\\\resizebox{\\\\linewidth}{!}{%\\n\\\\begin{tabular}{lrrrr|rrrr}\\n\\\\toprule\\nBenchmark & & \\\\multicolumn{3}{c|}{\\\\textbf{BRAGE}} & \\\\multicolumn{4}{c}{\\\\textbf{ScandEval}} \\\\\\\\\\nMetric(s) & & \\\\multicolumn{3}{c|}{} & \\\\makecell[c]{NorNE-nb} & \\\\makecell[c]{NoReC} & \\\\makecell[c]{NorQuAD} & \\\\makecell[c]{HellaSwag}\\\\\\\\\\n\\\\cmidrule(lr){3-5} \\\\cmidrule(lr){6-9}\\n\\\\textbf{Model} & \\\\textbf{Category} & \\\\textbf{Acc} & \\\\makecell[c]{\\\\textbf{Macro}\\\\\\\\\\\\textbf{F1}} & \\\\makecell[c]{\\\\textbf{MCC}} & \\\\makecell[c]{\\\\textbf{Micro}\\\\\\\\F1} & \\\\makecell[c]{\\\\textbf{Macro}\\\\\\\\\\\\textbf{F1}} & \\\\makecell[c]{\\\\textbf{F1}} & \\\\makecell[c]{\\\\textbf{Acc}} \\\\\\\\\\n',\n",
       " '\\\\bottomrule',\n",
       " '\\\\end{tabular}']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_prefix = \"\"\"\n",
    "\\\\begin{table*}[!htbp]\n",
    "    \\\\centering\n",
    "    \\\\resizebox{\\\\linewidth}{!}{%\n",
    "\\\\begin{tabular}{lrrrr|rrrr}\n",
    "\\\\toprule\n",
    "Benchmark & & \\\\multicolumn{3}{c|}{\\\\textbf{BRAGE}} & \\\\multicolumn{4}{c}{\\\\textbf{ScandEval}} \\\\\\\\\n",
    "Metric(s) & & \\\\multicolumn{3}{c|}{} & \\\\makecell[c]{NorNE-nb} & \\\\makecell[c]{NoReC} & \\\\makecell[c]{NorQuAD} & \\\\makecell[c]{HellaSwag}\\\\\\\\\n",
    "\\\\cmidrule(lr){3-5} \\\\cmidrule(lr){6-9}\n",
    "\\\\textbf{Model} & \\\\textbf{Category} & \\\\textbf{Acc} & \\\\makecell[c]{\\\\textbf{Macro}\\\\\\\\\\\\textbf{F1}} & \\\\makecell[c]{\\\\textbf{MCC}} & \\\\makecell[c]{\\\\textbf{Micro}\\\\\\\\F1} & \\\\makecell[c]{\\\\textbf{Macro}\\\\\\\\\\\\textbf{F1}} & \\\\makecell[c]{\\\\textbf{F1}} & \\\\makecell[c]{\\\\textbf{Acc}} \\\\\\\\\n",
    "\"\"\"\n",
    "latex_table_builder = [table_prefix]\n",
    "\n",
    "for category in sorted(set(model_tune_map.values())):\n",
    "    print(category)\n",
    "    subset = boldface[boldface[\"category\"] == category]\n",
    "    subset = subset.drop(columns=[\"category\"])\n",
    "    display(subset)\n",
    "    print(f\"\\\\multicolumn{9}{{l}}{{\\\\textbf{{Category: {category}}}}}\\\\\\\\\")\n",
    "    # to latex:\n",
    "    as_latex = subset.to_latex(index=False, escape=False, column_format=\"lrrrr|rrrr\")\n",
    "    print(as_latex)\n",
    "    print()\n",
    "    \n",
    "\n",
    "latex_table_builder.append(\"\\\\bottomrule\")\n",
    "latex_table_builder.append(\"\\\\end{tabular}\")\n",
    "latex_table_builder\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
