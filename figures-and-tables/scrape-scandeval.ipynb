{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['norwai/norwai-mistral-7b',\n",
       " 'norwai/norwai-mistral-7b-instruct',\n",
       " 'ruternorway/llama-2-13b-chat-norwegian',\n",
       " 'ruternorway/llama-2-7b-chat-norwegian',\n",
       " 'bineric/norskgpt-llama3-8b',\n",
       " 'bineric/norskgpt-mistral-7b',\n",
       " 'google/gemma-2-27b',\n",
       " 'google/gemma-2-27b-it',\n",
       " 'google/gemma-2-2b',\n",
       " 'google/gemma-2-2b-it',\n",
       " 'google/gemma-2-9b',\n",
       " 'google/gemma-2-9b-it',\n",
       " 'meta-llama/llama-2-13b-chat-hf',\n",
       " 'meta-llama/llama-2-7b-chat-hf',\n",
       " 'meta-llama/meta-llama-3-8b',\n",
       " 'meta-llama/meta-llama-3-8b-instruct',\n",
       " 'meta-llama/meta-llama-3.1-8b',\n",
       " 'meta-llama/meta-llama-3.1-8b-instruct',\n",
       " 'mistralai/mistral-7b-instruct-v0.1',\n",
       " 'mistralai/mistral-7b-v0.1',\n",
       " 'norallm/normistral-7b-scratch',\n",
       " 'norallm/normistral-7b-warm',\n",
       " 'norallm/normistral-7b-warm-instruct']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from consts import model_map\n",
    "used_models = sorted(list(model_map.keys()))\n",
    "used_models = [model.lower() for model in used_models]\n",
    "used_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECTED_MODELS = used_models  # specify a list of models to extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'google/gemma-2-27b-it', 'NorNE-nb': ' 56.75 ± 3.04', 'NoReC': ' 78.63 ± 0.96', 'NorQuAD': ' 73.41 ± 1.61', 'HellaSwag-no': ' 77.92 ± 1.72'}\n",
      "{'model': 'google/gemma-2-9b-it', 'NorNE-nb': ' 44.91 ± 3.62', 'NoReC': ' 73.45 ± 0.94', 'NorQuAD': ' 70.14 ± 1.53', 'HellaSwag-no': ' 75.79 ± 1.47'}\n",
      "{'model': 'google/gemma-2-27b', 'NorNE-nb': ' 43.06 ± 1.89', 'NoReC': ' 76.14 ± 1.68', 'NorQuAD': ' 80.21 ± 4.49', 'HellaSwag-no': ' 63.55 ± 4.76'}\n",
      "{'model': 'google/gemma-2-9b', 'NorNE-nb': ' 34.62 ± 1.80', 'NoReC': ' 75.53 ± 0.73', 'NorQuAD': ' 72.99 ± 3.16', 'HellaSwag-no': ' 63.52 ± 3.49'}\n",
      "{'model': 'bineric/NorskGPT-Llama3-8b', 'NorNE-nb': ' 60.25 ± 3.14', 'NoReC': ' 61.42 ± 3.56', 'NorQuAD': ' 74.57 ± 2.20', 'HellaSwag-no': ' 59.11 ± 2.44'}\n",
      "{'model': 'meta-llama/Meta-Llama-3.1-8B-Instruct', 'NorNE-nb': ' 71.87 ± 0.97', 'NoReC': ' 71.58 ± 0.90', 'NorQuAD': ' 70.96 ± 3.00', 'HellaSwag-no': ' 54.03 ± 0.82'}\n",
      "{'model': 'meta-llama/Meta-Llama-3.1-8B', 'NorNE-nb': ' 53.50 ± 3.27', 'NoReC': ' 68.71 ± 1.01', 'NorQuAD': ' 75.98 ± 2.62', 'HellaSwag-no': ' 46.84 ± 1.59'}\n",
      "{'model': 'bineric/NorskGPT-Mistral-7b', 'NorNE-nb': ' 47.72 ± 3.74', 'NoReC': ' 70.81 ± 1.30', 'NorQuAD': ' 74.38 ± 3.92', 'HellaSwag-no': ' 60.59 ± 1.18'}\n",
      "{'model': 'meta-llama/Meta-Llama-3-8B-Instruct', 'NorNE-nb': ' 65.57 ± 2.39', 'NoReC': ' 65.69 ± 3.50', 'NorQuAD': ' 69.90 ± 3.17', 'HellaSwag-no': ' 45.85 ± 1.93'}\n",
      "{'model': 'meta-llama/Meta-Llama-3-8B', 'NorNE-nb': ' 47.65 ± 2.94', 'NoReC': ' 66.15 ± 1.44', 'NorQuAD': ' 74.98 ± 3.70', 'HellaSwag-no': ' 42.47 ± 2.74'}\n",
      "{'model': 'mistralai/Mistral-7B-v0.1', 'NorNE-nb': ' 43.55 ± 2.21', 'NoReC': ' 64.53 ± 3.71', 'NorQuAD': ' 70.86 ± 2.79', 'HellaSwag-no': ' 32.43 ± 2.67'}\n",
      "{'model': 'meta-llama/Llama-2-13b-chat-hf', 'NorNE-nb': ' 40.40 ± 2.79', 'NoReC': ' 57.45 ± 3.77', 'NorQuAD': ' 69.24 ± 2.68', 'HellaSwag-no': ' 41.00 ± 1.40'}\n",
      "{'model': 'RuterNorway/Llama-2-13b-chat-norwegian', 'NorNE-nb': ' 47.74 ± 2.83', 'NoReC': ' 58.47 ± 3.79', 'NorQuAD': ' 65.76 ± 3.07', 'HellaSwag-no': ' 41.29 ± 1.19'}\n",
      "{'model': 'google/gemma-2-2b-it', 'NorNE-nb': ' 28.77 ± 2.22', 'NoReC': ' 63.18 ± 1.91', 'NorQuAD': ' 63.84 ± 1.50', 'HellaSwag-no': ' 49.42 ± 0.79'}\n",
      "{'model': 'mistralai/Mistral-7B-Instruct-v0.1', 'NorNE-nb': ' 34.52 ± 1.17', 'NoReC': ' 60.88 ± 1.36', 'NorQuAD': ' 63.67 ± 2.98', 'HellaSwag-no': ' 35.89 ± 1.06'}\n",
      "{'model': 'meta-llama/Llama-2-7b-chat-hf', 'NorNE-nb': ' 38.59 ± 2.84', 'NoReC': ' 57.09 ± 3.80', 'NorQuAD': ' 61.99 ± 2.34', 'HellaSwag-no': ' 31.84 ± 1.05'}\n",
      "{'model': 'NorwAI/NorwAI-Mistral-7B', 'NorNE-nb': ' 20.45 ± 2.65', 'NoReC': ' 65.98 ± 2.95', 'NorQuAD': ' 68.04 ± 5.37', 'HellaSwag-no': ' 27.82 ± 1.56'}\n",
      "{'model': 'norallm/normistral-7b-warm-instruct', 'NorNE-nb': ' 31.87 ± 1.92', 'NoReC': ' 43.91 ± 2.51', 'NorQuAD': ' 59.27 ± 1.53', 'HellaSwag-no': ' 29.64 ± 1.49'}\n",
      "{'model': 'google/gemma-2-2b', 'NorNE-nb': ' 21.28 ± 2.58', 'NoReC': ' 47.91 ± 2.11', 'NorQuAD': ' 63.31 ± 3.73', 'HellaSwag-no': ' 28.89 ± 1.54'}\n",
      "{'model': 'norallm/normistral-7b-warm', 'NorNE-nb': ' 31.45 ± 1.88', 'NoReC': ' 45.30 ± 3.46', 'NorQuAD': ' 61.85 ± 3.07', 'HellaSwag-no': ' 25.00 ± 0.83'}\n",
      "{'model': 'NorwAI/NorwAI-Mistral-7B-instruct', 'NorNE-nb': ' 24.26 ± 1.41', 'NoReC': ' 64.33 ± 2.80', 'NorQuAD': ' 29.01 ± 1.18', 'HellaSwag-no': ' 25.82 ± 0.79'}\n",
      "{'model': 'norallm/normistral-7b-scratch', 'NorNE-nb': ' 15.44 ± 5.52', 'NoReC': ' 36.85 ± 2.01', 'NorQuAD': ' 38.93 ± 2.59', 'HellaSwag-no': ' 24.84 ± 0.71'}\n",
      "{'model': 'RuterNorway/Llama-2-7b-chat-norwegian', 'NorNE-nb': ' 20.44 ± 2.47', 'NoReC': ' 23.50 ± 3.03', 'NorQuAD': ' 50.11 ± 1.80', 'HellaSwag-no': ' 24.48 ± 0.70'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "id = \"norwegian-nlg\"\n",
    "url = f\"https://scandeval.com/{id}/\"\n",
    "res = requests.get(url)\n",
    "soup = BeautifulSoup(res.content, \"html.parser\")\n",
    "table = soup.find(\"table\", {\"id\": {id}})\n",
    "data = []\n",
    "\n",
    "headers = []\n",
    "for th in table.find(\"thead\").find_all(\"th\"):\n",
    "    headers.append(th.text.strip())\n",
    "rows = table.find(\"tbody\").find_all(\"tr\")\n",
    "\n",
    "\n",
    "SELECTED_MODELS = used_models \n",
    "\n",
    "parsable_metrics = [\"NorNE-nb\", \"NoReC\", \"NorQuAD\", \"HellaSwag-no\"]\n",
    "def parse_metric(metric, value):\n",
    "    left, right = value.split(\"/\")\n",
    "    # VALUE ± STDDEV\n",
    "    lval, lstd = left.split(\"±\")\n",
    "    rval, rstd = right.split(\"±\")\n",
    "    lval = float(lval.strip())\n",
    "    rval = float(rval.strip())\n",
    "    lstd = float(lstd.strip())\n",
    "    rstd = float(rstd.strip())\n",
    "\n",
    "    # here goes some custom rules for parsing specific metrics...\n",
    "    match metric:\n",
    "        # micro-avg F1 with MISC tags -> difficult\n",
    "        case \"NorNE-nb\":\n",
    "            return right\n",
    "        # macro-avg F1\n",
    "        case \"NoReC\":\n",
    "            return right\n",
    "        # F1\n",
    "        case \"NorQuAD\":\n",
    "            return right\n",
    "        # accuracy\n",
    "        case \"HellaSwag-no\":\n",
    "            return right\n",
    "\n",
    "\n",
    "# skip Model (fist header), we do that manually :-)\n",
    "headers = [th.get_text(strip=True) for th in table.find_all(\"th\")][1:]\n",
    "# skip versions, if desired:\n",
    "headers = [h for h in headers if not \"version\" in h.lower()]\n",
    "\n",
    "\n",
    "for row in rows:\n",
    "    row_data = {}\n",
    "    cells = row.find_all(\"td\")\n",
    "    model_id = cells[0].text.strip()\n",
    "    # handle the <modelname> (few-shot) naming scheme)\n",
    "    model_id = model_id.split(\"(\")[0].strip()\n",
    "\n",
    "    if model_id.lower() not in SELECTED_MODELS:\n",
    "        continue\n",
    "\n",
    "    row_data[\"model\"] = model_id\n",
    "    for i, col in enumerate(headers):\n",
    "        value = cells[i + 1].text.strip()  # +1 as we added model already\n",
    "        if col in parsable_metrics:\n",
    "            row_data[col] = parse_metric(col, value)\n",
    "        else:\n",
    "            # you can add in other non-parsable metrics here/versions etc.\n",
    "            continue\n",
    "\n",
    "    data.append(row_data)\n",
    "\n",
    "for model_result in data:\n",
    "    print(model_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "current_date = datetime.now().strftime(\"%d-%m-%Y\")\n",
    "filename = f\"{id}-{current_date}.csv\"\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(filename, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
