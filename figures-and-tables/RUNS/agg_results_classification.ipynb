{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folders\n",
    "\n",
    "project_dir1 = \"2024-09-21_18-59-52_B2C_2024_constrained_3prompts_250maxtokens\"\n",
    "project_dir2 = \"2024-09-23_13-13-43_B2C_2024_constrained_3prompts_250maxtokens_gemmabase\"\n",
    "\n",
    "#project_dir3 = \"2024-10-01_09-24-20_B2C_2024_constrained_3prompts_250maxtokens_llama3\" # this run was a mistake\n",
    "\n",
    "project_dir3 = \"2024-10-01_11-30-25_B2C_2024_constrained_3prompts_250maxtokens_llama3\"\n",
    "\n",
    "project_dir4 = \"2024-10-08_14-20-12_B2C_2024_constrained_3prompts_250maxtokens_mistralv7b0.1\"\n",
    "project_dir5 = \"2024-10-09_06-05-37_B2C_2024_constrained_3prompts_250maxtokens_llama2\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load aggregated metrics for each run condition\n",
    "df1 = pd.read_hdf(project_dir1+\"/predictions.h5\", key='predictions')\n",
    "df1[\"project_dir\"] = project_dir1\n",
    "\n",
    "df2 = pd.read_hdf(project_dir2+\"/predictions.h5\", key='predictions')\n",
    "df2[\"project_dir\"] = project_dir2\n",
    "\n",
    "df3 = pd.read_hdf(project_dir3+\"/predictions.h5\", key='predictions')\n",
    "df3[\"project_dir\"] = project_dir3\n",
    "\n",
    "df4 = pd.read_hdf(project_dir4+\"/predictions.h5\", key='predictions')\n",
    "df4[\"project_dir\"] = project_dir4\n",
    "\n",
    "df5 = pd.read_hdf(project_dir5+\"/predictions.h5\", key='predictions')\n",
    "df5[\"project_dir\"] = project_dir5\n",
    "\n",
    "df = pd.concat([df1, df2, df3, df4, df5])\n",
    "df = df.loc[df.prompt == \"full_description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RuterNorway/Llama-2-7b-chat-norwegian',\n",
       " 'RuterNorway/Llama-2-13b-chat-norwegian',\n",
       " 'norallm/normistral-7b-warm-instruct',\n",
       " 'norallm/normistral-7b-warm',\n",
       " 'norallm/normistral-7b-scratch',\n",
       " 'NorwAI/NorwAI-Mistral-7B-instruct',\n",
       " 'NorwAI/NorwAI-Mistral-7B',\n",
       " 'bineric/NorskGPT-Llama3-8b',\n",
       " 'bineric/NorskGPT-Mistral-7b',\n",
       " 'mistralai/Mistral-7B-v0.1',\n",
       " 'meta-llama/Meta-Llama-3.1-8B',\n",
       " 'meta-llama/Meta-Llama-3.1-8B-Instruct',\n",
       " 'google/gemma-2-2b-it',\n",
       " 'google/gemma-2-9b-it',\n",
       " 'google/gemma-2-27b-it',\n",
       " 'google/gemma-2-2b',\n",
       " 'google/gemma-2-9b',\n",
       " 'google/gemma-2-27b',\n",
       " 'meta-llama/Meta-Llama-3-8B',\n",
       " 'meta-llama/Meta-Llama-3-8B-Instruct',\n",
       " 'mistralai/Mistral-7B-Instruct-v0.1',\n",
       " 'meta-llama/Llama-2-7b-chat-hf',\n",
       " 'meta-llama/Llama-2-13b-chat-hf']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "individual_models = df.model.unique().tolist()\n",
    "individual_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model\n",
       "RuterNorway/Llama-2-7b-chat-norwegian     3000\n",
       "google/gemma-2-2b-it                      3000\n",
       "meta-llama/Llama-2-7b-chat-hf             3000\n",
       "mistralai/Mistral-7B-Instruct-v0.1        3000\n",
       "meta-llama/Meta-Llama-3-8B-Instruct       3000\n",
       "meta-llama/Meta-Llama-3-8B                3000\n",
       "google/gemma-2-27b                        3000\n",
       "google/gemma-2-9b                         3000\n",
       "google/gemma-2-2b                         3000\n",
       "google/gemma-2-27b-it                     3000\n",
       "google/gemma-2-9b-it                      3000\n",
       "meta-llama/Meta-Llama-3.1-8B-Instruct     3000\n",
       "RuterNorway/Llama-2-13b-chat-norwegian    3000\n",
       "meta-llama/Meta-Llama-3.1-8B              3000\n",
       "mistralai/Mistral-7B-v0.1                 3000\n",
       "bineric/NorskGPT-Mistral-7b               3000\n",
       "bineric/NorskGPT-Llama3-8b                3000\n",
       "NorwAI/NorwAI-Mistral-7B                  3000\n",
       "NorwAI/NorwAI-Mistral-7B-instruct         3000\n",
       "norallm/normistral-7b-scratch             3000\n",
       "norallm/normistral-7b-warm                3000\n",
       "norallm/normistral-7b-warm-instruct       3000\n",
       "meta-llama/Llama-2-13b-chat-hf            3000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.model.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['replication',\n",
       " 'server',\n",
       " 'model',\n",
       " 'model_type',\n",
       " 'chat_format',\n",
       " 'prompt',\n",
       " 'dataset',\n",
       " 'task_id',\n",
       " 'duration_sec',\n",
       " 'vram_used_gb',\n",
       " 'ram_used_gb',\n",
       " 'raw_tokens',\n",
       " 'n_trunc_tokens',\n",
       " 'input_text',\n",
       " 'prompt_text',\n",
       " 'predicted_label',\n",
       " 'actual_label',\n",
       " 'RUN',\n",
       " 'project_dir']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-21_18-59-52_B2C_2024_constrained_3prompts_250maxtokens\n",
      "2024-09-23_13-13-43_B2C_2024_constrained_3prompts_250maxtokens_gemmabase\n",
      "2024-10-01_11-30-25_B2C_2024_constrained_3prompts_250maxtokens_llama3\n",
      "2024-10-08_14-20-12_B2C_2024_constrained_3prompts_250maxtokens_mistralv7b0.1\n",
      "2024-10-09_06-05-37_B2C_2024_constrained_3prompts_250maxtokens_llama2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Replication</th>\n",
       "      <th>Batchname</th>\n",
       "      <th>N_samples_per_rep</th>\n",
       "      <th>Run</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RuterNorway/Llama-2-7b-chat-norwegian</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-09-21_18-59-52_B2C_2024_constrained_3prom...</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RuterNorway/Llama-2-7b-chat-norwegian</td>\n",
       "      <td>0.076667</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-09-21_18-59-52_B2C_2024_constrained_3prom...</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RuterNorway/Llama-2-7b-chat-norwegian</td>\n",
       "      <td>0.093333</td>\n",
       "      <td>2</td>\n",
       "      <td>2024-09-21_18-59-52_B2C_2024_constrained_3prom...</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RuterNorway/Llama-2-7b-chat-norwegian</td>\n",
       "      <td>0.093333</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-09-21_18-59-52_B2C_2024_constrained_3prom...</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RuterNorway/Llama-2-7b-chat-norwegian</td>\n",
       "      <td>0.103333</td>\n",
       "      <td>4</td>\n",
       "      <td>2024-09-21_18-59-52_B2C_2024_constrained_3prom...</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>meta-llama/Llama-2-13b-chat-hf</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>5</td>\n",
       "      <td>2024-10-09_06-05-37_B2C_2024_constrained_3prom...</td>\n",
       "      <td>300</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>meta-llama/Llama-2-13b-chat-hf</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>6</td>\n",
       "      <td>2024-10-09_06-05-37_B2C_2024_constrained_3prom...</td>\n",
       "      <td>300</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>meta-llama/Llama-2-13b-chat-hf</td>\n",
       "      <td>0.093333</td>\n",
       "      <td>7</td>\n",
       "      <td>2024-10-09_06-05-37_B2C_2024_constrained_3prom...</td>\n",
       "      <td>300</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>meta-llama/Llama-2-13b-chat-hf</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>8</td>\n",
       "      <td>2024-10-09_06-05-37_B2C_2024_constrained_3prom...</td>\n",
       "      <td>300</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>meta-llama/Llama-2-13b-chat-hf</td>\n",
       "      <td>0.086667</td>\n",
       "      <td>9</td>\n",
       "      <td>2024-10-09_06-05-37_B2C_2024_constrained_3prom...</td>\n",
       "      <td>300</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>230 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Model  Accuracy  Replication  \\\n",
       "0    RuterNorway/Llama-2-7b-chat-norwegian  0.110000            0   \n",
       "1    RuterNorway/Llama-2-7b-chat-norwegian  0.076667            1   \n",
       "2    RuterNorway/Llama-2-7b-chat-norwegian  0.093333            2   \n",
       "3    RuterNorway/Llama-2-7b-chat-norwegian  0.093333            3   \n",
       "4    RuterNorway/Llama-2-7b-chat-norwegian  0.103333            4   \n",
       "..                                     ...       ...          ...   \n",
       "225         meta-llama/Llama-2-13b-chat-hf  0.083333            5   \n",
       "226         meta-llama/Llama-2-13b-chat-hf  0.090000            6   \n",
       "227         meta-llama/Llama-2-13b-chat-hf  0.093333            7   \n",
       "228         meta-llama/Llama-2-13b-chat-hf  0.090000            8   \n",
       "229         meta-llama/Llama-2-13b-chat-hf  0.086667            9   \n",
       "\n",
       "                                             Batchname  N_samples_per_rep  Run  \n",
       "0    2024-09-21_18-59-52_B2C_2024_constrained_3prom...                300    0  \n",
       "1    2024-09-21_18-59-52_B2C_2024_constrained_3prom...                300    0  \n",
       "2    2024-09-21_18-59-52_B2C_2024_constrained_3prom...                300    0  \n",
       "3    2024-09-21_18-59-52_B2C_2024_constrained_3prom...                300    0  \n",
       "4    2024-09-21_18-59-52_B2C_2024_constrained_3prom...                300    0  \n",
       "..                                                 ...                ...  ...  \n",
       "225  2024-10-09_06-05-37_B2C_2024_constrained_3prom...                300   22  \n",
       "226  2024-10-09_06-05-37_B2C_2024_constrained_3prom...                300   22  \n",
       "227  2024-10-09_06-05-37_B2C_2024_constrained_3prom...                300   22  \n",
       "228  2024-10-09_06-05-37_B2C_2024_constrained_3prom...                300   22  \n",
       "229  2024-10-09_06-05-37_B2C_2024_constrained_3prom...                300   22  \n",
       "\n",
       "[230 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Calculate accuracy statistics for each model\n",
    "models = []\n",
    "replications = []\n",
    "accuracies = []\n",
    "batchnames = []\n",
    "n_samples_per_rep = []\n",
    "\n",
    "run_idx = 0\n",
    "runs = []\n",
    "\n",
    "for batchname in df.project_dir.unique():\n",
    "    # get the subset for the current batch\n",
    "    batch = df[df.project_dir == batchname]\n",
    "    print(batchname)\n",
    "\n",
    "    # for each model in the current batch\n",
    "    for model in batch.model.unique():\n",
    "        # subset on the current model\n",
    "        experiment = batch[batch.model == model]\n",
    "\n",
    "        for rep in experiment.replication.unique():\n",
    "            # get the subset for the current replication\n",
    "            subset_rep = experiment[experiment.replication == rep]\n",
    "\n",
    "            # get the accuracy for the current replication\n",
    "            accuracy = accuracy_score(subset_rep.actual_label, subset_rep.predicted_label)\n",
    "            #print(f\"Replication {rep}: Accuracy = {accuracy}\")\n",
    "\n",
    "            # append the accuracy to the list\n",
    "            accuracies.append(accuracy)\n",
    "            models.append(model)\n",
    "            replications.append(rep)\n",
    "            batchnames.append(batchname)\n",
    "            n_samples_per_rep.append(len(subset_rep))\n",
    "            runs.append(run_idx)\n",
    "\n",
    "\n",
    "        run_idx += 1\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "        'Model': models,\n",
    "        'Accuracy': accuracies,\n",
    "        'Replication': replications,\n",
    "        'Batchname': batchnames,\n",
    "        'N_samples_per_rep': n_samples_per_rep,\n",
    "        'Run': runs\n",
    "    })\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add macro f1 and mcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-21_18-59-52_B2C_2024_constrained_3prompts_250maxtokens\n",
      "2024-09-23_13-13-43_B2C_2024_constrained_3prompts_250maxtokens_gemmabase\n",
      "2024-10-01_11-30-25_B2C_2024_constrained_3prompts_250maxtokens_llama3\n",
      "2024-10-08_14-20-12_B2C_2024_constrained_3prompts_250maxtokens_mistralv7b0.1\n",
      "2024-10-09_06-05-37_B2C_2024_constrained_3prompts_250maxtokens_llama2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, matthews_corrcoef\n",
    "\n",
    "# Calculate accuracy statistics for each model\n",
    "models = []\n",
    "replications = []\n",
    "accuracies = []\n",
    "macro_f1s = []  # New list for macro-F1 scores\n",
    "mccs = []       # New list for MCC scores\n",
    "batchnames = []\n",
    "n_samples_per_rep = []\n",
    "\n",
    "run_idx = 0\n",
    "runs = []\n",
    "\n",
    "for batchname in df.project_dir.unique():\n",
    "    # get the subset for the current batch\n",
    "    batch = df[df.project_dir == batchname]\n",
    "    print(batchname)\n",
    "\n",
    "    # for each model in the current batch\n",
    "    for model in batch.model.unique():\n",
    "        # subset on the current model\n",
    "        experiment = batch[batch.model == model]\n",
    "\n",
    "        for rep in experiment.replication.unique():\n",
    "            # get the subset for the current replication\n",
    "            subset_rep = experiment[experiment.replication == rep]\n",
    "\n",
    "            # get the metrics for the current replication\n",
    "            accuracy = accuracy_score(subset_rep.actual_label, subset_rep.predicted_label)\n",
    "            macro_f1 = f1_score(subset_rep.actual_label, subset_rep.predicted_label, average='macro')\n",
    "            mcc = matthews_corrcoef(subset_rep.actual_label, subset_rep.predicted_label)\n",
    "\n",
    "            # append the metrics to the lists\n",
    "            accuracies.append(accuracy)\n",
    "            macro_f1s.append(macro_f1)\n",
    "            mccs.append(mcc)\n",
    "            models.append(model)\n",
    "            replications.append(rep)\n",
    "            batchnames.append(batchname)\n",
    "            n_samples_per_rep.append(len(subset_rep))\n",
    "            runs.append(run_idx)\n",
    "\n",
    "        run_idx += 1\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "        'Run': runs,\n",
    "        'Model': models,\n",
    "        'Accuracy': accuracies,\n",
    "        'Macro_F1': macro_f1s,\n",
    "        'MCC': mccs,\n",
    "        'Replication': replications,\n",
    "        'Batchname': batchnames,\n",
    "        'N_samples': n_samples_per_rep\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Run</th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro_F1</th>\n",
       "      <th>MCC</th>\n",
       "      <th>Replication</th>\n",
       "      <th>Batchname</th>\n",
       "      <th>N_samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>RuterNorway/Llama-2-7b-chat-norwegian</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.086561</td>\n",
       "      <td>0.019310</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-09-21_18-59-52_B2C_2024_constrained_3prom...</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>RuterNorway/Llama-2-7b-chat-norwegian</td>\n",
       "      <td>0.076667</td>\n",
       "      <td>0.064123</td>\n",
       "      <td>-0.014177</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-09-21_18-59-52_B2C_2024_constrained_3prom...</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>RuterNorway/Llama-2-7b-chat-norwegian</td>\n",
       "      <td>0.093333</td>\n",
       "      <td>0.074088</td>\n",
       "      <td>0.025923</td>\n",
       "      <td>2</td>\n",
       "      <td>2024-09-21_18-59-52_B2C_2024_constrained_3prom...</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>RuterNorway/Llama-2-7b-chat-norwegian</td>\n",
       "      <td>0.093333</td>\n",
       "      <td>0.067452</td>\n",
       "      <td>0.013570</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-09-21_18-59-52_B2C_2024_constrained_3prom...</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>RuterNorway/Llama-2-7b-chat-norwegian</td>\n",
       "      <td>0.103333</td>\n",
       "      <td>0.076782</td>\n",
       "      <td>0.018998</td>\n",
       "      <td>4</td>\n",
       "      <td>2024-09-21_18-59-52_B2C_2024_constrained_3prom...</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>22</td>\n",
       "      <td>meta-llama/Llama-2-13b-chat-hf</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.051163</td>\n",
       "      <td>-0.006759</td>\n",
       "      <td>5</td>\n",
       "      <td>2024-10-09_06-05-37_B2C_2024_constrained_3prom...</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>22</td>\n",
       "      <td>meta-llama/Llama-2-13b-chat-hf</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.062541</td>\n",
       "      <td>-0.026294</td>\n",
       "      <td>6</td>\n",
       "      <td>2024-10-09_06-05-37_B2C_2024_constrained_3prom...</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>22</td>\n",
       "      <td>meta-llama/Llama-2-13b-chat-hf</td>\n",
       "      <td>0.093333</td>\n",
       "      <td>0.083634</td>\n",
       "      <td>0.023295</td>\n",
       "      <td>7</td>\n",
       "      <td>2024-10-09_06-05-37_B2C_2024_constrained_3prom...</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>22</td>\n",
       "      <td>meta-llama/Llama-2-13b-chat-hf</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.063708</td>\n",
       "      <td>0.001198</td>\n",
       "      <td>8</td>\n",
       "      <td>2024-10-09_06-05-37_B2C_2024_constrained_3prom...</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>22</td>\n",
       "      <td>meta-llama/Llama-2-13b-chat-hf</td>\n",
       "      <td>0.086667</td>\n",
       "      <td>0.052422</td>\n",
       "      <td>-0.000822</td>\n",
       "      <td>9</td>\n",
       "      <td>2024-10-09_06-05-37_B2C_2024_constrained_3prom...</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>230 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Run                                  Model  Accuracy  Macro_F1       MCC  \\\n",
       "0      0  RuterNorway/Llama-2-7b-chat-norwegian  0.110000  0.086561  0.019310   \n",
       "1      0  RuterNorway/Llama-2-7b-chat-norwegian  0.076667  0.064123 -0.014177   \n",
       "2      0  RuterNorway/Llama-2-7b-chat-norwegian  0.093333  0.074088  0.025923   \n",
       "3      0  RuterNorway/Llama-2-7b-chat-norwegian  0.093333  0.067452  0.013570   \n",
       "4      0  RuterNorway/Llama-2-7b-chat-norwegian  0.103333  0.076782  0.018998   \n",
       "..   ...                                    ...       ...       ...       ...   \n",
       "225   22         meta-llama/Llama-2-13b-chat-hf  0.083333  0.051163 -0.006759   \n",
       "226   22         meta-llama/Llama-2-13b-chat-hf  0.090000  0.062541 -0.026294   \n",
       "227   22         meta-llama/Llama-2-13b-chat-hf  0.093333  0.083634  0.023295   \n",
       "228   22         meta-llama/Llama-2-13b-chat-hf  0.090000  0.063708  0.001198   \n",
       "229   22         meta-llama/Llama-2-13b-chat-hf  0.086667  0.052422 -0.000822   \n",
       "\n",
       "     Replication                                          Batchname  N_samples  \n",
       "0              0  2024-09-21_18-59-52_B2C_2024_constrained_3prom...        300  \n",
       "1              1  2024-09-21_18-59-52_B2C_2024_constrained_3prom...        300  \n",
       "2              2  2024-09-21_18-59-52_B2C_2024_constrained_3prom...        300  \n",
       "3              3  2024-09-21_18-59-52_B2C_2024_constrained_3prom...        300  \n",
       "4              4  2024-09-21_18-59-52_B2C_2024_constrained_3prom...        300  \n",
       "..           ...                                                ...        ...  \n",
       "225            5  2024-10-09_06-05-37_B2C_2024_constrained_3prom...        300  \n",
       "226            6  2024-10-09_06-05-37_B2C_2024_constrained_3prom...        300  \n",
       "227            7  2024-10-09_06-05-37_B2C_2024_constrained_3prom...        300  \n",
       "228            8  2024-10-09_06-05-37_B2C_2024_constrained_3prom...        300  \n",
       "229            9  2024-10-09_06-05-37_B2C_2024_constrained_3prom...        300  \n",
       "\n",
       "[230 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_excel(\"results_11_01_2025.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_interval_radius(raw_scores: list[float]) -> float:\n",
    "    \"\"\"Compute the radius of a 95% confidence interval.\n",
    "\n",
    "    Args:\n",
    "        raw_scores:\n",
    "            The scores that we need to compute the interval for.\n",
    "\n",
    "    Returns:\n",
    "        The radius of the interval.\n",
    "    \"\"\"\n",
    "    sample_std_dev = np.std(raw_scores, ddof=1)\n",
    "    std_err = sample_std_dev / np.sqrt(len(raw_scores))\n",
    "    return 1.96 * std_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>model</th>\n",
       "      <th>mean_acc</th>\n",
       "      <th>mean_acc_ci</th>\n",
       "      <th>mean_Macro_F1</th>\n",
       "      <th>mean_Macro_F1_ci</th>\n",
       "      <th>mean_MCC</th>\n",
       "      <th>mean_MCC_ci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>RuterNorway/Llama-2-7b-chat-norwegian</td>\n",
       "      <td>0.1080</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0280</td>\n",
       "      <td>0.0151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>RuterNorway/Llama-2-13b-chat-norwegian</td>\n",
       "      <td>0.2327</td>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.1979</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.1459</td>\n",
       "      <td>0.0205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>norallm/normistral-7b-warm-instruct</td>\n",
       "      <td>0.1830</td>\n",
       "      <td>0.0134</td>\n",
       "      <td>0.0972</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>norallm/normistral-7b-warm</td>\n",
       "      <td>0.1783</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.1376</td>\n",
       "      <td>0.0127</td>\n",
       "      <td>0.0231</td>\n",
       "      <td>0.0154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>norallm/normistral-7b-scratch</td>\n",
       "      <td>0.1647</td>\n",
       "      <td>0.0109</td>\n",
       "      <td>0.1389</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.0151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>NorwAI/NorwAI-Mistral-7B-instruct</td>\n",
       "      <td>0.1717</td>\n",
       "      <td>0.0169</td>\n",
       "      <td>0.1355</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>0.0167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>NorwAI/NorwAI-Mistral-7B</td>\n",
       "      <td>0.1683</td>\n",
       "      <td>0.0119</td>\n",
       "      <td>0.1255</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.0146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>bineric/NorskGPT-Llama3-8b</td>\n",
       "      <td>0.1687</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>0.1514</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0614</td>\n",
       "      <td>0.0190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>bineric/NorskGPT-Mistral-7b</td>\n",
       "      <td>0.3050</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.2689</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.2254</td>\n",
       "      <td>0.0147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>mistralai/Mistral-7B-v0.1</td>\n",
       "      <td>0.1287</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.1031</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>-0.0020</td>\n",
       "      <td>0.0062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>meta-llama/Meta-Llama-3.1-8B</td>\n",
       "      <td>0.1707</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.1448</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0436</td>\n",
       "      <td>0.0170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>meta-llama/Meta-Llama-3.1-8B-Instruct</td>\n",
       "      <td>0.2487</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.2180</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.1638</td>\n",
       "      <td>0.0193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>google/gemma-2-2b-it</td>\n",
       "      <td>0.4353</td>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.3262</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.3325</td>\n",
       "      <td>0.0187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>google/gemma-2-9b-it</td>\n",
       "      <td>0.6210</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.5350</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.5513</td>\n",
       "      <td>0.0191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>google/gemma-2-27b-it</td>\n",
       "      <td>0.6053</td>\n",
       "      <td>0.0231</td>\n",
       "      <td>0.5056</td>\n",
       "      <td>0.0154</td>\n",
       "      <td>0.5427</td>\n",
       "      <td>0.0213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>google/gemma-2-2b</td>\n",
       "      <td>0.1643</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.1308</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.0498</td>\n",
       "      <td>0.0134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>google/gemma-2-9b</td>\n",
       "      <td>0.2080</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.1702</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0751</td>\n",
       "      <td>0.0141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>google/gemma-2-27b</td>\n",
       "      <td>0.1507</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.1397</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B</td>\n",
       "      <td>0.1623</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.1416</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0338</td>\n",
       "      <td>0.0157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B-Instruct</td>\n",
       "      <td>0.3303</td>\n",
       "      <td>0.0134</td>\n",
       "      <td>0.2644</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.2538</td>\n",
       "      <td>0.0167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.1</td>\n",
       "      <td>0.2360</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.1733</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.0886</td>\n",
       "      <td>0.0233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>meta-llama/Llama-2-7b-chat-hf</td>\n",
       "      <td>0.0640</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.0269</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>meta-llama/Llama-2-13b-chat-hf</td>\n",
       "      <td>0.0893</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0612</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>-0.0069</td>\n",
       "      <td>0.0136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    run                                   model  mean_acc  mean_acc_ci  \\\n",
       "0     0   RuterNorway/Llama-2-7b-chat-norwegian    0.1080       0.0114   \n",
       "1     1  RuterNorway/Llama-2-13b-chat-norwegian    0.2327       0.0198   \n",
       "2     2     norallm/normistral-7b-warm-instruct    0.1830       0.0134   \n",
       "3     3              norallm/normistral-7b-warm    0.1783       0.0129   \n",
       "4     4           norallm/normistral-7b-scratch    0.1647       0.0109   \n",
       "5     5       NorwAI/NorwAI-Mistral-7B-instruct    0.1717       0.0169   \n",
       "6     6                NorwAI/NorwAI-Mistral-7B    0.1683       0.0119   \n",
       "7     7              bineric/NorskGPT-Llama3-8b    0.1687       0.0151   \n",
       "8     8             bineric/NorskGPT-Mistral-7b    0.3050       0.0091   \n",
       "9     9               mistralai/Mistral-7B-v0.1    0.1287       0.0074   \n",
       "10   10            meta-llama/Meta-Llama-3.1-8B    0.1707       0.0143   \n",
       "11   11   meta-llama/Meta-Llama-3.1-8B-Instruct    0.2487       0.0113   \n",
       "12   12                    google/gemma-2-2b-it    0.4353       0.0215   \n",
       "13   13                    google/gemma-2-9b-it    0.6210       0.0180   \n",
       "14   14                   google/gemma-2-27b-it    0.6053       0.0231   \n",
       "15   15                       google/gemma-2-2b    0.1643       0.0100   \n",
       "16   16                       google/gemma-2-9b    0.2080       0.0131   \n",
       "17   17                      google/gemma-2-27b    0.1507       0.0085   \n",
       "18   18              meta-llama/Meta-Llama-3-8B    0.1623       0.0135   \n",
       "19   19     meta-llama/Meta-Llama-3-8B-Instruct    0.3303       0.0134   \n",
       "20   20      mistralai/Mistral-7B-Instruct-v0.1    0.2360       0.0174   \n",
       "21   21           meta-llama/Llama-2-7b-chat-hf    0.0640       0.0071   \n",
       "22   22          meta-llama/Llama-2-13b-chat-hf    0.0893       0.0077   \n",
       "\n",
       "    mean_Macro_F1  mean_Macro_F1_ci  mean_MCC  mean_MCC_ci  \n",
       "0          0.0869            0.0129    0.0280       0.0151  \n",
       "1          0.1979            0.0110    0.1459       0.0205  \n",
       "2          0.0972            0.0083    0.0131       0.0125  \n",
       "3          0.1376            0.0127    0.0231       0.0154  \n",
       "4          0.1389            0.0141    0.0199       0.0151  \n",
       "5          0.1355            0.0149    0.0258       0.0167  \n",
       "6          0.1255            0.0124    0.0122       0.0146  \n",
       "7          0.1514            0.0150    0.0614       0.0190  \n",
       "8          0.2689            0.0105    0.2254       0.0147  \n",
       "9          0.1031            0.0073   -0.0020       0.0062  \n",
       "10         0.1448            0.0149    0.0436       0.0170  \n",
       "11         0.2180            0.0136    0.1638       0.0193  \n",
       "12         0.3262            0.0150    0.3325       0.0187  \n",
       "13         0.5350            0.0150    0.5513       0.0191  \n",
       "14         0.5056            0.0154    0.5427       0.0213  \n",
       "15         0.1308            0.0102    0.0498       0.0134  \n",
       "16         0.1702            0.0120    0.0751       0.0141  \n",
       "17         0.1397            0.0096    0.0608       0.0106  \n",
       "18         0.1416            0.0118    0.0338       0.0157  \n",
       "19         0.2644            0.0123    0.2538       0.0167  \n",
       "20         0.1733            0.0181    0.0886       0.0233  \n",
       "21         0.0269            0.0041    0.0008       0.0132  \n",
       "22         0.0612            0.0085   -0.0069       0.0136  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decimals = 4\n",
    "\n",
    "results_list = []\n",
    "\n",
    "for run in results_df.Run.unique():\n",
    "    subset = results_df[results_df.Run == run]\n",
    "    \n",
    "    res = {\"run\":run,\n",
    "          \"model\":subset.Model.unique().tolist()[0],\n",
    "          \"mean_acc\":np.round(np.mean(subset.Accuracy),decimals),\n",
    "          \"mean_acc_ci\":np.round(compute_interval_radius(subset.Accuracy),decimals),\n",
    "          \"mean_Macro_F1\":np.round(np.mean(subset.Macro_F1),decimals),\n",
    "          \"mean_Macro_F1_ci\":np.round(compute_interval_radius(subset.Macro_F1),decimals),        \n",
    "          \"mean_MCC\":np.round(np.mean(subset.MCC),decimals),\n",
    "          \"mean_MCC_ci\":np.round(compute_interval_radius(subset.MCC),decimals)\n",
    "    }   \n",
    "    results_list.append(res)\n",
    "\n",
    "agg_results = pd.DataFrame(results_list)\n",
    "agg_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RuterNorway/Llama-2-7b-chat-norwegian',\n",
       " 'RuterNorway/Llama-2-13b-chat-norwegian',\n",
       " 'norallm/normistral-7b-warm-instruct',\n",
       " 'norallm/normistral-7b-warm',\n",
       " 'norallm/normistral-7b-scratch',\n",
       " 'NorwAI/NorwAI-Mistral-7B-instruct',\n",
       " 'NorwAI/NorwAI-Mistral-7B',\n",
       " 'bineric/NorskGPT-Llama3-8b',\n",
       " 'bineric/NorskGPT-Mistral-7b',\n",
       " 'mistralai/Mistral-7B-v0.1',\n",
       " 'meta-llama/Meta-Llama-3.1-8B',\n",
       " 'meta-llama/Meta-Llama-3.1-8B-Instruct',\n",
       " 'google/gemma-2-2b-it',\n",
       " 'google/gemma-2-9b-it',\n",
       " 'google/gemma-2-27b-it',\n",
       " 'google/gemma-2-2b',\n",
       " 'google/gemma-2-9b',\n",
       " 'google/gemma-2-27b',\n",
       " 'meta-llama/Meta-Llama-3-8B',\n",
       " 'meta-llama/Meta-Llama-3-8B-Instruct',\n",
       " 'mistralai/Mistral-7B-Instruct-v0.1',\n",
       " 'meta-llama/Llama-2-7b-chat-hf',\n",
       " 'meta-llama/Llama-2-13b-chat-hf']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_results.model.unique().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_order = [\"google/gemma-2-27b-it\",\n",
    "         \"google/gemma-2-2b-it\",\n",
    "         \"google/gemma-2-9b-it\",\n",
    "         \"meta-llama/Llama-2-13b-chat-hf\",\n",
    "         \"meta-llama/Llama-2-7b-chat-hf\", \n",
    "         \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "         \"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "         \"mistralai/Mistral-7B-Instruct-v0.1\",\n",
    "         \n",
    "         \"RuterNorway/Llama-2-13b-chat-norwegian\",\n",
    "         \"RuterNorway/Llama-2-7b-chat-norwegian\",\n",
    "         \"bineric/NorskGPT-Llama3-8b\",\n",
    "         \"bineric/NorskGPT-Mistral-7b\",\n",
    "         \n",
    "         \"google/gemma-2-27b\",\n",
    "         \"google/gemma-2-2b\",\n",
    "         \"google/gemma-2-9b\",\n",
    "         \n",
    "         \"meta-llama/Meta-Llama-3-8B\",\n",
    "         \"meta-llama/Meta-Llama-3.1-8B\",\n",
    "         'mistralai/Mistral-7B-v0.1',\n",
    "\n",
    "         \"norallm/normistral-7b-scratch\",\n",
    "         \"norallm/normistral-7b-warm\",\n",
    "         \"NorwAI/NorwAI-Mistral-7B\", \n",
    "\n",
    "         \"norallm/normistral-7b-warm-instruct\",\n",
    "         \"NorwAI/NorwAI-Mistral-7B-instruct\"\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a categorical type with custom ordering\n",
    "agg_results['model'] = pd.Categorical(\n",
    "    agg_results['model'],\n",
    "    categories=model_order,\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "# Sort the dataframe by the model column\n",
    "agg_results = agg_results.sort_values('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_results.to_excel(\"agg_results_11_01_2025.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>model</th>\n",
       "      <th>mean_acc</th>\n",
       "      <th>mean_acc_ci</th>\n",
       "      <th>mean_Macro_F1</th>\n",
       "      <th>mean_Macro_F1_ci</th>\n",
       "      <th>mean_MCC</th>\n",
       "      <th>mean_MCC_ci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>google/gemma-2-27b-it</td>\n",
       "      <td>0.6053</td>\n",
       "      <td>0.0231</td>\n",
       "      <td>0.5056</td>\n",
       "      <td>0.0154</td>\n",
       "      <td>0.5427</td>\n",
       "      <td>0.0213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>google/gemma-2-2b-it</td>\n",
       "      <td>0.4353</td>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.3262</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.3325</td>\n",
       "      <td>0.0187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>google/gemma-2-9b-it</td>\n",
       "      <td>0.6210</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.5350</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.5513</td>\n",
       "      <td>0.0191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>meta-llama/Llama-2-13b-chat-hf</td>\n",
       "      <td>0.0893</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0612</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>-0.0069</td>\n",
       "      <td>0.0136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>meta-llama/Llama-2-7b-chat-hf</td>\n",
       "      <td>0.0640</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.0269</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B-Instruct</td>\n",
       "      <td>0.3303</td>\n",
       "      <td>0.0134</td>\n",
       "      <td>0.2644</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.2538</td>\n",
       "      <td>0.0167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>meta-llama/Meta-Llama-3.1-8B-Instruct</td>\n",
       "      <td>0.2487</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.2180</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.1638</td>\n",
       "      <td>0.0193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.1</td>\n",
       "      <td>0.2360</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.1733</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.0886</td>\n",
       "      <td>0.0233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>RuterNorway/Llama-2-13b-chat-norwegian</td>\n",
       "      <td>0.2327</td>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.1979</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.1459</td>\n",
       "      <td>0.0205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>RuterNorway/Llama-2-7b-chat-norwegian</td>\n",
       "      <td>0.1080</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0280</td>\n",
       "      <td>0.0151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>bineric/NorskGPT-Llama3-8b</td>\n",
       "      <td>0.1687</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>0.1514</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0614</td>\n",
       "      <td>0.0190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>bineric/NorskGPT-Mistral-7b</td>\n",
       "      <td>0.3050</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.2689</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.2254</td>\n",
       "      <td>0.0147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>google/gemma-2-27b</td>\n",
       "      <td>0.1507</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.1397</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>google/gemma-2-2b</td>\n",
       "      <td>0.1643</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.1308</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.0498</td>\n",
       "      <td>0.0134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>google/gemma-2-9b</td>\n",
       "      <td>0.2080</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.1702</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0751</td>\n",
       "      <td>0.0141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B</td>\n",
       "      <td>0.1623</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.1416</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0338</td>\n",
       "      <td>0.0157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>meta-llama/Meta-Llama-3.1-8B</td>\n",
       "      <td>0.1707</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.1448</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0436</td>\n",
       "      <td>0.0170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>mistralai/Mistral-7B-v0.1</td>\n",
       "      <td>0.1287</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.1031</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>-0.0020</td>\n",
       "      <td>0.0062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>norallm/normistral-7b-scratch</td>\n",
       "      <td>0.1647</td>\n",
       "      <td>0.0109</td>\n",
       "      <td>0.1389</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.0151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>norallm/normistral-7b-warm</td>\n",
       "      <td>0.1783</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.1376</td>\n",
       "      <td>0.0127</td>\n",
       "      <td>0.0231</td>\n",
       "      <td>0.0154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>NorwAI/NorwAI-Mistral-7B</td>\n",
       "      <td>0.1683</td>\n",
       "      <td>0.0119</td>\n",
       "      <td>0.1255</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.0146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>norallm/normistral-7b-warm-instruct</td>\n",
       "      <td>0.1830</td>\n",
       "      <td>0.0134</td>\n",
       "      <td>0.0972</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>NorwAI/NorwAI-Mistral-7B-instruct</td>\n",
       "      <td>0.1717</td>\n",
       "      <td>0.0169</td>\n",
       "      <td>0.1355</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>0.0167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    run                                   model  mean_acc  mean_acc_ci  \\\n",
       "14   14                   google/gemma-2-27b-it    0.6053       0.0231   \n",
       "12   12                    google/gemma-2-2b-it    0.4353       0.0215   \n",
       "13   13                    google/gemma-2-9b-it    0.6210       0.0180   \n",
       "22   22          meta-llama/Llama-2-13b-chat-hf    0.0893       0.0077   \n",
       "21   21           meta-llama/Llama-2-7b-chat-hf    0.0640       0.0071   \n",
       "19   19     meta-llama/Meta-Llama-3-8B-Instruct    0.3303       0.0134   \n",
       "11   11   meta-llama/Meta-Llama-3.1-8B-Instruct    0.2487       0.0113   \n",
       "20   20      mistralai/Mistral-7B-Instruct-v0.1    0.2360       0.0174   \n",
       "1     1  RuterNorway/Llama-2-13b-chat-norwegian    0.2327       0.0198   \n",
       "0     0   RuterNorway/Llama-2-7b-chat-norwegian    0.1080       0.0114   \n",
       "7     7              bineric/NorskGPT-Llama3-8b    0.1687       0.0151   \n",
       "8     8             bineric/NorskGPT-Mistral-7b    0.3050       0.0091   \n",
       "17   17                      google/gemma-2-27b    0.1507       0.0085   \n",
       "15   15                       google/gemma-2-2b    0.1643       0.0100   \n",
       "16   16                       google/gemma-2-9b    0.2080       0.0131   \n",
       "18   18              meta-llama/Meta-Llama-3-8B    0.1623       0.0135   \n",
       "10   10            meta-llama/Meta-Llama-3.1-8B    0.1707       0.0143   \n",
       "9     9               mistralai/Mistral-7B-v0.1    0.1287       0.0074   \n",
       "4     4           norallm/normistral-7b-scratch    0.1647       0.0109   \n",
       "3     3              norallm/normistral-7b-warm    0.1783       0.0129   \n",
       "6     6                NorwAI/NorwAI-Mistral-7B    0.1683       0.0119   \n",
       "2     2     norallm/normistral-7b-warm-instruct    0.1830       0.0134   \n",
       "5     5       NorwAI/NorwAI-Mistral-7B-instruct    0.1717       0.0169   \n",
       "\n",
       "    mean_Macro_F1  mean_Macro_F1_ci  mean_MCC  mean_MCC_ci  \n",
       "14         0.5056            0.0154    0.5427       0.0213  \n",
       "12         0.3262            0.0150    0.3325       0.0187  \n",
       "13         0.5350            0.0150    0.5513       0.0191  \n",
       "22         0.0612            0.0085   -0.0069       0.0136  \n",
       "21         0.0269            0.0041    0.0008       0.0132  \n",
       "19         0.2644            0.0123    0.2538       0.0167  \n",
       "11         0.2180            0.0136    0.1638       0.0193  \n",
       "20         0.1733            0.0181    0.0886       0.0233  \n",
       "1          0.1979            0.0110    0.1459       0.0205  \n",
       "0          0.0869            0.0129    0.0280       0.0151  \n",
       "7          0.1514            0.0150    0.0614       0.0190  \n",
       "8          0.2689            0.0105    0.2254       0.0147  \n",
       "17         0.1397            0.0096    0.0608       0.0106  \n",
       "15         0.1308            0.0102    0.0498       0.0134  \n",
       "16         0.1702            0.0120    0.0751       0.0141  \n",
       "18         0.1416            0.0118    0.0338       0.0157  \n",
       "10         0.1448            0.0149    0.0436       0.0170  \n",
       "9          0.1031            0.0073   -0.0020       0.0062  \n",
       "4          0.1389            0.0141    0.0199       0.0151  \n",
       "3          0.1376            0.0127    0.0231       0.0154  \n",
       "6          0.1255            0.0124    0.0122       0.0146  \n",
       "2          0.0972            0.0083    0.0131       0.0125  \n",
       "5          0.1355            0.0149    0.0258       0.0167  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BRAGE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
